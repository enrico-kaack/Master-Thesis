\section{Research Questions}

\begin{description}
    \item[RQ1] Can the Clean Code Analysis Platform be a useful addition to developers workflow besides existing tools? 
\end{description}

\subsection{RQ1: Can the Clean Code Analysis Platform be a useful addition to developers workflow besides existing tools?}
\paragraph{Motivation}
Several tools are established that aim to improve code quality and detect unclean code. Every new tool with similiar claims has to proove its usefulnes besides the preexisting tools. We compare the CCAP with existing tools based on the design goals expandability, useability and integration as well as (useful features in existing tools the CCAP was not planned for).
\paragraph{Approach}
To evaluate, if the CCAP is a useful addition, we compare different features to see, if it can supplement or replace existing tools. As described in section TODO, the compared tools are Sonarcube, PMD Source Code Analyser Project, Codacy and PyLint.

\paragraph{Results}
Table TODO shows a summary of the features.

\subparagraph{Finding 1: Expandability}
For expandability of analysis plugins, CCAP is compareable to PyLint, that also offer plugins to analse the raw string, the token stream or the AST. PMD allows plugins to analyse the AST or define XPath rules. Since XPath rules can be used in the CCAP as well (using a third-party library in the plugin), PMD offers less expandsion possiblities. Sonarqube on the other hand provides the richest possibilities for extension. Not only can developers analyse the AST, specify XPath rules, but they have access to an additional semantic model of the code that provides direct access to methods, parameters, return values etc. This simplifies analysis in comparison to the AST analysis. Additionaly, Sonarqube allows plugins to expose an API for other plugins to use. This different type of plugin further increases the possibilites for rule checking plugins. The least expandability offers Codacy, that allow customizing or disabling existing rules, but does not offer to add rules to the existing rule set.

Regarding output plugins, no compared tool offers the output customization of CCAP. PMD and PyLint have different predefined output formats like json, html, csv or text. Although PyLint allows customizing the message format using a formatting string as command-line argument, they do not offer an extension possibility for the output. Sonarqube displays the analysis reports in its WebUi. The scanner tool, SonarScanner, sends the reports to the server component, that renders the results in the browser.  Codacys local scanner produces text output, the cloud version also has a WebUi.

\subparagraph{Finding 2: Integration shortcomings}
The CCAP has major shortcomings in its integrations into IDEs, build processes and CI pipelines. All contestant tools provide plugins for build systems like Gradle or Maven. Except Codacy, all tools have IDE integrations into the most common editors. Sonarqube and Codacy have integrations into source control systems. Same applies to PMD and PyLint, since they are included in Codacy and therefore have the same integrations. --> Community, matureity

\subparagraph{Finding 3: Useability}
For a plugin developer, the useability of the plugin system is simple for CCAP and PyLint. Both tools have the same plugin mechanism and a simple plugin interface to work with. PMD has a similar, straightforward plugin interface, but its Java plugin has to be bundeled into a jar file before adding to the classpath. The latter applies to Sonarqube as well; Additionaly the powerful and rich plugin API makes it harder to use.

For the user, installing CCAP is like installing every other python package. Running from the command-line is fast and can be automated e.g. using git pre-commit hooks. The same worklow would be archieved with PyLint. Sonarqube is more complex to install on own systems due to its multiple components, but after the set-up, the WebUi and integrations into most developer worklow have the best useability. Codacy as a cloud service only requires permission to access the source code repository to start scanning the code.

\subparagraph{Finding 4: Multi-Language scanning}
Sonarqube, PMD and Codacy offers multi-language scanning. This is advantagous for code repositories with multiple languages and for reusing the same tools and infrastructure for multiple projects with different programming languages. Supporting multi-language scanning is not possible with CCAP and would require a redefinition of the architecture. Although multi-language support was not a design goal, it would be a major advantage for adoption.

\subparagraph{Finding 5: Matureity and Community-Support}
The matureity and community-support of tools really impact the integration of the tools into the developer workflow. Some integrations are community-made and shared, so everybody has an advantage. The community support would also be neccessary for CCAP to write and share additional analysis plugins and to integrate into different workflows.

\paragraph{Summary}
In summary, CCAP offers a good, but not best in class expandability with analysis plugins. It has a high useability for plugin developer and for users. The lack of community support and matureity reflects in the lack of integrations for different workflows. 
We see the CCAP as an addition to the powerful Sonarqube. The shortcomings of Sonarqube in its powerful, but complex expandability could be supplemented with the simple, yet powerful expandability of the CCAP as a local tool to run prior to commits. For instance, a code reviewer could code problematic code into a simple python plugin, distributes it to the team and would hopefully not encounter the same problem again.
Additionaly, the CCAP could be used to teach about Clean Code and to enforce specific coding rules to student, since the local setup is simple and Clean Code rules could be turned into analysis plugins by students or teachers without having to understand a complex interface.