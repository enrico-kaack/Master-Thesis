\section*{Zusammenfassung}

Die automatische Erkennung von Verstößen gegen die Clean Codes Prinizpien ermöglicht es Entwicklern, die Verständlichkeit und Lesbarkeit von Quellcode leicht zu verbessern. Wir führen eine Systematik ein, bei der wir die Clean Code Regeln basierend auf der Komplexität eines automatischen Erkennungsverfahren einordnen. Darüber hinaus entwerfen und implementieren wir eine Plattform, die das Orchestrieren verschiedener, automatischer Erkennungsverfahren ermöglicht. Als nächstes trainieren wir verschiedene Verfahren des maschinellen Lernens zur Erkennung von Code Mustern, die Clean Code Regeln verletzen: Einen Support-Vector-Klassifikator (1), der die Code Muster nicht zufriedenstellend erkennen kann. Ein auf LSTMs basierendes neuronales Netzwerk (2), welches alle anderen Modelle übertrifft, aber empfindlich gegenüber weniger Trainingsdaten ist. Einen Random-Forest Klassifikator (3), der moderate Ungleichheit in der Klassenhäufigkeit in den Trainingsdaten kompensieren kann und einen Gradient-Boosting Klassifikator (4), der nicht empfindlich gegenüber Ungleichheit in der Klassenhäufigkeit ist. Durch das Hinzufügen von unbekannten Problemvariationen untersuchen wir, ob die Modelle die Struktur des zugrunde liegenden Problems gelernt haben. Unsere Ergebnisse zeigen, dass die Modelle die unbekannten Variationen schlecht erkennen können und nur das Muster statt der Struktur des Problems gelernt haben. Zur Verbesserung schlagen wir eine Veränderung der Kodierung des Codes für die Modelle vor, die einen größeren Fokus auf die Struktur des Codes legt. Außerdem empfehlen wir das Hinzufügen von weiteren Variationen durch händisch gesammelte Daten.
 
\newpage
\section*{Abstract}    
The automatic detection of clean code violations enables developers to improve understandability and readability of source code more easily. We propose a taxonomy for clean code rule based on the assumed level of complexity for an automated checker. Furthermore, design and implement a platform to orchestrate automated rule checkers and find that it offers a simple way of extension compared to other platforms. Next, we train different machine learning models on the task to detect code patterns that violate clean code rules: A support vector classifier (1) that is not able to detect violations with acceptable performance. An LSTM-based neural network (2) that outperforms all other models, but is sensitive towards less training data. A random forest classifier (3) that can handle a moderate class imbalance in the training data, and a gradient boosting classifier (4) that is insensitive towards class imbalance. By introducing unseen variations, we further investigate if the models have learnt the structure of the problem. We find that the models do not perform well on unseen problem variations and only learnt the problem pattern. We suggest improvements by changing the encoding to emphasise code structure and by adding hand-labelled data with more variations.