
@article{allamanis_learning_2018,
  title = {Learning to {{Represent Programs}} with {{Graphs}}},
  author = {Allamanis, Miltiadis and Brockschmidt, Marc and Khademi, Mahmoud},
  date = {2018-05-04},
  url = {http://arxiv.org/abs/1711.00740},
  urldate = {2020-08-02},
  abstract = {Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code’s known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures. In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VARNAMING, in which a network attempts to predict the name of a variable given its usage, and VARMISUSE, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VARMISUSE task in many cases. Additionally, our testing showed that VARMISUSE identifies a number of bugs in mature open-source projects.},
  archivePrefix = {arXiv},
  eprint = {1711.00740},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/6WWJP2AN/Allamanis et al. - 2018 - Learning to Represent Programs with Graphs.pdf},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Programming Languages,Computer Science - Software Engineering},
  langid = {english},
  primaryClass = {cs}
}

@article{alon_code2seq_2019,
  title = {Code2seq: {{Generating Sequences}} from {{Structured Representations}} of {{Code}}},
  shorttitle = {Code2seq},
  author = {Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran},
  date = {2019-02-21},
  url = {http://arxiv.org/abs/1808.01400},
  urldate = {2020-08-02},
  abstract = {The ability to generate natural language sequences from source code snippets has a variety of applications such as code summarization, documentation, and retrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine translation (NMT), have achieved state-of-the-art performance on these tasks by treating source code as a sequence of tokens. We present CODE2SEQ: an alternative approach that leverages the syntactic structure of programming languages to better encode source code. Our model represents a code snippet as the set of compositional paths in its abstract syntax tree (AST) and uses attention to select the relevant paths while decoding. We demonstrate the effectiveness of our approach for two tasks, two programming languages, and four datasets of up to 16M examples. Our model significantly outperforms previous models that were specifically designed for programming languages, as well as state-of-the-art NMT models. An online demo of our model is available at http://code2seq.org. Our code, data and trained models are available at http://github.com/tech-srl/code2seq.},
  archivePrefix = {arXiv},
  eprint = {1808.01400},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/JGI2N2UI/Alon et al. - 2019 - code2seq Generating Sequences from Structured Rep.pdf},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages,Statistics - Machine Learning},
  langid = {english},
  primaryClass = {cs, stat}
}

@article{alon_code2vec_2018,
  title = {Code2vec: {{Learning Distributed Representations}} of {{Code}}},
  shorttitle = {Code2vec},
  author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
  date = {2018-10-30},
  url = {http://arxiv.org/abs/1803.09473},
  urldate = {2020-08-02},
  abstract = {We present a neural model for representing snippets of code as continuous distributed vectors (“code embeddings”). The main idea is to represent a code snippet as a single fixed-length code vector, which can be used to predict semantic properties of the snippet. This is performed by decomposing code to a collection of paths in its abstract syntax tree, and learning the atomic representation of each path simultaneously with learning how to aggregate a set of them. We demonstrate the effectiveness of our approach by using it to predict a method’s name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 14M methods. We show that code vectors trained on this dataset can predict method names from files that were completely unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies. Comparing previous techniques over the same data set, our approach obtains a relative improvement of over 75\%, being the first to successfully predict method names based on a large, cross-project, corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data and trained models are available at https://github.com/tech-srl/code2vec.},
  archivePrefix = {arXiv},
  eprint = {1803.09473},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/YRQYVA3F/Alon et al. - 2018 - code2vec Learning Distributed Representations of .pdf},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Programming Languages,Statistics - Machine Learning},
  langid = {english},
  primaryClass = {cs, stat}
}

@article{alon_general_2018,
  title = {A {{General Path}}-{{Based Representation}} for {{Predicting Program Properties}}},
  author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
  date = {2018-04-22},
  url = {http://arxiv.org/abs/1803.09544},
  urldate = {2020-08-02},
  abstract = {Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens.},
  archivePrefix = {arXiv},
  eprint = {1803.09544},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/9AURHKYP/Alon et al. - 2018 - A General Path-Based Representation for Predicting.pdf},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages},
  langid = {english},
  primaryClass = {cs}
}

@article{alon_structural_2020,
  title = {Structural {{Language Models}} of {{Code}}},
  author = {Alon, Uri and Sadaka, Roy and Levy, Omer and Yahav, Eran},
  date = {2020-02-07},
  url = {http://arxiv.org/abs/1910.00577},
  urldate = {2020-02-28},
  abstract = {We address the problem of any-code completion - generating a missing piece of source code in a given program without any restriction on the vocabulary or structure. We introduce a new approach to any-code completion that leverages the strict syntax of programming languages to model a code snippet as a tree - structural language modeling (SLM). SLM estimates the probability of the program's abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. We present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous techniques that have severely restricted the kinds of expressions that can be generated in this task, our approach can generate arbitrary code in any programming language. Our model significantly outperforms both seq2seq and a variety of structured approaches in generating Java and C\# code. We make our code, datasets, and models publicly available.},
  archivePrefix = {arXiv},
  eprint = {1910.00577},
  eprinttype = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages,Statistics - Machine Learning}
}

@inproceedings{asaduzzaman_context-sensitive_2014,
  title = {Context-{{Sensitive Code Completion Tool}} for {{Better API Usability}}},
  booktitle = {2014 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}} ({{ICSME}})},
  author = {Asaduzzaman, M. and Roy, C.K. and Schneider, K.A. and Hou, Daqing},
  date = {2014-09},
  pages = {621--624},
  doi = {10.1109/ICSME.2014.110},
  abstract = {Developers depend on APIs of frameworks and libraries to support the development process. Due to the large number of existing APIs, it is difficult to learn, remember, and use them during the development of a software. To mitigate the problem, modern integrated development environments provide code completion facilities that free developers from remembering every detail. In this paper, we introduce CSCC, a simple, efficient context-sensitive code completion tool that leverages previous code examples to support method completion. Compared to other existing code completion tools, CSCC uses new sources of contextual information together with lightweight source code analysis to better recommend API method calls.},
  eventtitle = {2014 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}} ({{ICSME}})},
  keywords = {_tablet,API methods,API usability,application program interfaces,code completion,Context,Context modeling,context-sensitive code completion tool,CSCC,Databases,Eclipse plugin,Java,libraries,lightweight source code analysis,Proposals,Receivers,source code (software)}
}

@article{babii_modeling_2019,
  title = {Modeling {{Vocabulary}} for {{Big Code Machine Learning}}},
  author = {Babii, Hlib and Janes, Andrea and Robbes, Romain},
  date = {2019-04-03},
  url = {http://arxiv.org/abs/1904.01873},
  urldate = {2020-08-02},
  abstract = {When building machine learning models that operate on source code, several decisions have to be made to model source-code vocabulary. These decisions can have a large impact: some can lead to not being able to train models at all, others significantly affect performance, particularly for Neural Language Models. Yet, these decisions are not often fully described. This paper lists important modeling choices for source code vocabulary, and explores their impact on the resulting vocabulary on a large-scale corpus of 14,436 projects. We show that a subset of decisions have decisive characteristics, allowing to train accurate Neural Language Models quickly on a large corpus of 10,106 projects.},
  archivePrefix = {arXiv},
  eprint = {1904.01873},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/GMNMUM5Q/Babii et al. - 2019 - Modeling Vocabulary for Big Code Machine Learning.pdf},
  keywords = {Computer Science - Computation and Language,Computer Science - Software Engineering},
  langid = {english},
  primaryClass = {cs}
}

@article{baggen_standardized_2012,
  title = {Standardized Code Quality Benchmarking for Improving Software Maintainability},
  author = {Baggen, Robert and Correia, José Pedro and Schill, Katrin and Visser, Joost},
  date = {2012},
  journaltitle = {Software Quality Journal},
  volume = {20},
  pages = {287--307},
  publisher = {{Springer}},
  file = {/home/enrico/Zotero/storage/LH4HVAVP/Baggen et al. - 2012 - Standardized code quality benchmarking for improvi.pdf},
  number = {2}
}

@article{bhoopchand_learning_2016,
  title = {Learning {{Python Code Suggestion}} with a {{Sparse Pointer Network}}},
  author = {Bhoopchand, Avishkar and Rocktäschel, Tim and Barr, Earl and Riedel, Sebastian},
  date = {2016-11-24},
  url = {http://arxiv.org/abs/1611.08307},
  urldate = {2019-12-03},
  abstract = {To enhance developer productivity, all modern integrated development environments (IDEs) include code suggestion functionality that proposes likely next tokens at the cursor. While current IDEs work well for statically-typed languages, their reliance on type annotations means that they do not provide the same level of support for dynamic programming languages as for statically-typed languages. Moreover, suggestion engines in modern IDEs do not propose expressions or multi-statement idiomatic code. Recent work has shown that language models can improve code suggestion systems by learning from software repositories. This paper introduces a neural language model with a sparse pointer network aimed at capturing very long-range dependencies. We release a large-scale code suggestion corpus of 41M lines of Python code crawled from GitHub. On this corpus, we found standard neural language models to perform well at suggesting local phenomena, but struggle to refer to identifiers that are introduced many tokens in the past. By augmenting a neural language model with a pointer network specialized in referring to predefined classes of identifiers, we obtain a much lower perplexity and a 5 percentage points increase in accuracy for code suggestion compared to an LSTM baseline. In fact, this increase in code suggestion accuracy is due to a 13 times more accurate prediction of identifiers. Furthermore, a qualitative analysis shows this model indeed captures interesting long-range dependencies, like referring to a class member defined over 60 tokens in the past.},
  archivePrefix = {arXiv},
  eprint = {1611.08307},
  eprinttype = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Neural and Evolutionary Computing,Computer Science - Software Engineering}
}

@inproceedings{bielik_phog_2016,
  title = {{{PHOG}}: {{Probabilistic Model}} for {{Code}}},
  shorttitle = {{{PHOG}}},
  booktitle = {Proceedings of the 33rd {{International Conference}} on {{International Conference}} on {{Machine Learning}} - {{Volume}} 48},
  author = {Bielik, Pavol and Raychev, Veselin and Vechev, Martin},
  date = {2016},
  pages = {2933--2942},
  publisher = {{JMLR.org}},
  url = {http://dl.acm.org/citation.cfm?id=3045390.3045699},
  urldate = {2019-11-09},
  abstract = {We introduce a new generative model for code called probabilistic higher order grammar (PHOG). PHOG generalizes probabilistic context free grammars (PCFGs) by allowing conditioning of a production rule beyond the parent non-terminal, thus capturing rich contexts relevant to programs. Even though PHOG is more powerful than a PCFG, it can be learned from data just as efficiently. We trained a PHOG model on a large JavaScript code corpus and show that it is more precise than existing models, while similarly fast. As a result, PHOG can immediately benefit existing programming tools based on probabilistic models of code.},
  series = {{{ICML}}'16}
}

@article{bobadilla_collaborative_2012,
  title = {A {{Collaborative Filtering Approach}} to {{Mitigate}} the {{New User Cold Start Problem}}},
  author = {Bobadilla, Jesús and Ortega, Fernando and Hernando, Antonio and Bernal, Jesús},
  date = {2012-02},
  journaltitle = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {26},
  pages = {225--238},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2011.07.021},
  url = {http://www.sciencedirect.com/science/article/pii/S0950705111001882},
  urldate = {2016-02-08},
  abstract = {The new user cold start issue represents a serious problem in recommender systems as it can lead to the loss of new users who decide to stop using the system due to the lack of accuracy in the recommendations received in that first stage in which they have not yet cast a significant number of votes with which to feed the recommender system’s collaborative filtering core. For this reason it is particularly important to design new similarity metrics which provide greater precision in the results offered to users who have cast few votes. This paper presents a new similarity measure perfected using optimization based on neural learning, which exceeds the best results obtained with current metrics. The metric has been tested on the Netflix and Movielens databases, obtaining important improvements in the measures of accuracy, precision and recall when applied to new user cold start situations. The paper includes the mathematical formalization describing how to obtain the main quality measures of a recommender system using leave-one-out cross validation.},
  keywords = {Cold start,collaborative filtering,Leave-one-out-cross validation,Neural learning,recommender systems,Similarity measures}
}

@article{brockschmidt_generative_2018,
  title = {Generative {{Code Modeling}} with {{Graphs}}},
  author = {Brockschmidt, Marc and Allamanis, Miltiadis and Gaunt, Alexander L. and Polozov, Oleksandr},
  date = {2018-05-22},
  url = {http://arxiv.org/abs/1805.08490},
  urldate = {2018-07-12},
  abstract = {Generative models for source code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. The generative procedure interleaves grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions, outperforming a range of strong baselines.},
  archivePrefix = {arXiv},
  eprint = {1805.08490},
  eprinttype = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages,Statistics - Machine Learning}
}

@article{brockschmidt_generative_2019,
  title = {{{GENERATIVE CODE MODELING WITH GRAPHS}}},
  author = {Brockschmidt, Marc and Allamanis, Miltiadis and Gaunt, Alexander and Polozov, Oleksandr},
  date = {2019},
  pages = {24},
  abstract = {Generative models for source code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. Our model generates code by interleaving grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions, outperforming a range of strong baselines.},
  file = {/home/enrico/Zotero/storage/AKKUQ459/Brockschmidt et al. - 2019 - GENERATIVE CODE MODELING WITH GRAPHS.pdf},
  langid = {english}
}

@inproceedings{bruch_learning_2009,
  title = {Learning from {{Examples}} to {{Improve Code Completion Systems}}},
  booktitle = {Proceedings of the the 7th {{Joint Meeting}} of the {{European Software Engineering Conference}} and the {{ACM SIGSOFT Symposium}} on {{The Foundations}} of {{Software Engineering}}},
  author = {Bruch, Marcel and Monperrus, Martin and Mezini, Mira},
  date = {2009},
  pages = {213--222},
  publisher = {{ACM}},
  doi = {10.1145/1595696.1595728},
  url = {http://doi.acm.org/10.1145/1595696.1595728},
  urldate = {2015-12-02},
  abstract = {The suggestions made by current IDE's code completion features are based exclusively on static type system of the programming language. As a result, often proposals are made which are irrelevant for a particular working context. Also, these suggestions are ordered alphabetically rather than by their relevance in a particular context. In this paper, we present intelligent code completion systems that learn from existing code repositories. We have implemented three such systems, each using the information contained in repositories in a different way. We perform a large-scale quantitative evaluation of these systems, integrate the best performing one into Eclipse, and evaluate the latter also by a user study. Our experiments give evidence that intelligent code completion systems which learn from examples significantly outperform mainstream code completion systems in terms of the relevance of their suggestions and thus have the potential to enhance developers' productivity.},
  isbn = {978-1-60558-001-2},
  keywords = {_tablet,code completion,code recommender,content assist,integrated development environment},
  series = {{{ESEC}}/{{FSE}} '09},
  venue = {New York, NY, USA}
}

@inproceedings{buch_learning-based_2019,
  title = {Learning-{{Based Recursive Aggregation}} of {{Abstract Syntax Trees}} for {{Code Clone Detection}}},
  booktitle = {2019 {{IEEE}} 26th {{International Conference}} on {{Software Analysis}}, {{Evolution}} and {{Reengineering}} ({{SANER}})},
  author = {Buch, Lutz and Andrzejak, Artur},
  date = {2019-02},
  pages = {95--104},
  publisher = {{IEEE}},
  location = {{Hangzhou, China}},
  doi = {10.1109/SANER.2019.8668039},
  url = {https://ieeexplore.ieee.org/document/8668039/},
  urldate = {2020-08-02},
  abstract = {Code clone detection remains a crucial challenge in maintaining software projects. Many classic approaches rely on handcrafted aggregation schemes, while recent work uses supervised or unsupervised learning. In this work, we study several aspects of aggregation schemes for code clone detection based on supervised learning. To this aim, we implement an AST-based Recursive Neural Network. Firstly, our ablation study shows the influence of model choices and hyperparameters. We introduce error scaling as a way to effectively and efficiently address the class imbalance problem arising in code clone detection. Secondly, we study the influence of pretrained embeddings representing nodes in ASTs. We show that simply averaging all node vectors of a given AST yields strong baseline aggregation scheme. Further, learned AST aggregation schemes greatly benefit from pretrained node embeddings. Finally, we show the importance of carefully separating training and test data by clone clusters, to reliably measure generalization of models learned with supervision.},
  eventtitle = {2019 {{IEEE}} 26th {{International Conference}} on {{Software Analysis}}, {{Evolution}} and {{Reengineering}} ({{SANER}})},
  file = {/home/enrico/Zotero/storage/MQQNFFDW/Buch und Andrzejak - 2019 - Learning-Based Recursive Aggregation of Abstract S.pdf},
  isbn = {978-1-72810-591-8},
  langid = {english}
}

@article{dai_transformer-xl_2019,
  title = {Transformer-{{XL}}: {{Attentive Language Models Beyond}} a {{Fixed}}-{{Length Context}}},
  shorttitle = {Transformer-{{XL}}},
  author = {Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V. and Salakhutdinov, Ruslan},
  date = {2019-06-02},
  url = {http://arxiv.org/abs/1901.02860},
  urldate = {2020-08-02},
  abstract = {Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, TransformerXL learns dependency that is 80\% longer than RNNs and 450\% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-ofthe-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch1.},
  archivePrefix = {arXiv},
  eprint = {1901.02860},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/SJYYNQ6I/Dai et al. - 2019 - Transformer-XL Attentive Language Models Beyond a.pdf},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  langid = {english},
  primaryClass = {cs, stat}
}

@article{dam_deep_2016,
  title = {A Deep Language Model for Software Code},
  author = {Dam, Hoa Khanh and Tran, Truyen and Pham, Trang},
  date = {2016-08-09},
  url = {http://arxiv.org/abs/1608.02715},
  urldate = {2020-08-02},
  abstract = {Existing language models such as n-grams for software code often fail to capture a long context where dependent code elements scatter far apart. In this paper, we propose a novel approach to build a language model for software code to address this particular issue. Our language model, partly inspired by human memory, is built upon the powerful deep learning-based Long Short Term Memory architecture that is capable of learning long-term dependencies which occur frequently in software code. Results from our intrinsic evaluation on a corpus of Java projects have demonstrated the effectiveness of our language model. This work contributes to realizing our vision for DeepSoft, an end-to-end, generic deep learning-based framework for modeling software and its development process.},
  archivePrefix = {arXiv},
  eprint = {1608.02715},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/BC8FUFQM/Dam et al. - 2016 - A deep language model for software code.pdf},
  keywords = {Computer Science - Software Engineering,Statistics - Machine Learning},
  langid = {english},
  primaryClass = {cs, stat}
}

@inproceedings{delaitre_evaluating_2015,
  title = {Evaluating {{Bug Finders}} -- {{Test}} and {{Measurement}} of {{Static Code Analyzers}}},
  booktitle = {2015 {{IEEE}}/{{ACM}} 1st {{International Workshop}} on {{Complex Faults}} and {{Failures}} in {{Large Software Systems}} ({{COUFLESS}})},
  author = {Delaitre, Aurelien and Stivalet, Bertrand and Fong, Elizabeth and Okun, Vadim},
  date = {2015-05},
  pages = {14--20},
  publisher = {{IEEE}},
  location = {{Florence, Italy}},
  doi = {10.1109/COUFLESS.2015.10},
  url = {http://ieeexplore.ieee.org/document/7181477/},
  urldate = {2020-08-11},
  abstract = {Software static analysis is one of many options for finding bugs in software. Like compilers, static analyzers take a program as input. This paper covers tools that examine source codewithout executing itand output bug reports. Static analysis is a complex and generally undecidable problem. Most tools resort to approximation to overcome these obstacles and it sometimes leads to incorrect results. Therefore, tool effectiveness needs to be evaluated. Several characteristics of the tools should be examined. First, what types of bugs can they find? Second, what proportion of bugs do they report? Third, what percentage of findings is correct? These questions can be answered by one or more metrics. But to calculate these, we need test cases having certain characteristics: statistical significance, ground truth, and relevance. Test cases with all three attributes are out of reach, but we can use combinations of only two to calculate the metrics.},
  eventtitle = {2015 {{IEEE}}/{{ACM}} 1st {{International Workshop}} on {{Complex Faults}} and {{Failures}} in {{Large Software Systems}} ({{COUFLESS}})},
  file = {/home/enrico/Zotero/storage/UVV954XA/Delaitre et al. - 2015 - Evaluating Bug Finders -- Test and Measurement of .pdf},
  isbn = {978-1-4673-7034-9},
  langid = {english}
}

@article{eyal_salman_identification_2017,
  title = {Identification {{Multi}}-{{Level Frequent Usage Patterns}} from {{APIs}}},
  author = {Eyal Salman, Hamzeh},
  date = {2017-08-01},
  journaltitle = {Journal of Systems and Software},
  shortjournal = {Journal of Systems and Software},
  volume = {130},
  pages = {42--56},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2017.05.039},
  url = {http://www.sciencedirect.com/science/article/pii/S0164121217300869},
  urldate = {2019-03-24},
  abstract = {Software developers increasingly rely on application programming interfaces (APIs) of frameworks to increase productivity. An API method is generally used within code snippets along with other methods of the API of interest. When developers invoke API methods in a framework, they often encounter difficulty to determine which methods to call due to the huge number of included methods in that API. Developers usually exploit a source code search tool searching for code snippets that use the API methods of interest. However, the number of returned code snippets is very large which hinders the developer to locate useful ones. Moreover, co-usage relationships between API methods are often not documented. This article presents an approach to identify multi-level frequent usage patterns (IML-FUP) to help developers understand API usage and facilitate the development tasks when they use new APIs. An identified pattern represents a set of API methods that are frequently called together across interfering usage scenarios. In order to investigate the efficiency of the proposed approach, an experimental evaluation is conducted using four APIs and 89 client programs. For all studied APIs, the experimental results show that the proposed approach identifies usage patterns that are always strongly cohesive and highly consistent.},
  keywords = {API documentation,API usage,Formal concept analysis,Identification,Usage patterns}
}

@article{feng_codebert_2020,
  title = {{{CodeBERT}}: {{A Pre}}-{{Trained Model}} for {{Programming}} and {{Natural Languages}}},
  shorttitle = {{{CodeBERT}}},
  author = {Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and Zhou, Ming},
  date = {2020-04-27},
  url = {http://arxiv.org/abs/2002.08155},
  urldate = {2020-08-02},
  abstract = {We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL). CodeBERT learns generalpurpose representations that support downstream NL-PL applications such as natural language code search, code documentation generation, etc. We develop CodeBERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators. This enables us to utilize both “bimodal” data of NLPL pairs and “unimodal” data, where the former provides input tokens for model training while the latter helps to learn better generators. We evaluate CodeBERT on two NL-PL applications by fine-tuning model parameters. Results show that CodeBERT achieves state-of-the-art performance on both natural language code search and code documentation generation. Furthermore, to investigate what type of knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and evaluate in a zero-shot setting where parameters of pre-trained models are fixed. Results show that CodeBERT performs better than previous pre-trained models on NL-PL probing.},
  archivePrefix = {arXiv},
  eprint = {2002.08155},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/DWHALAFF/Feng et al. - 2020 - CodeBERT A Pre-Trained Model for Programming and .pdf},
  keywords = {Computer Science - Computation and Language,Computer Science - Programming Languages},
  langid = {english},
  primaryClass = {cs}
}

@online{gerrand_error_2011,
  title = {Error Handling and {{Go}}},
  author = {Gerrand, Andrew},
  date = {2011-07-12},
  url = {https://blog.golang.org/error-handling-and-go},
  type = {The Go Blog}
}

@article{hegedus_empirical_2018,
  title = {Empirical Evaluation of Software Maintainability Based on a Manually Validated Refactoring Dataset},
  author = {Hegedűs, Péter and Kádár, István and Ferenc, Rudolf and Gyimóthy, Tibor},
  date = {2018-03},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  volume = {95},
  pages = {313--327},
  issn = {09505849},
  doi = {10.1016/j.infsof.2017.11.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584916303561},
  urldate = {2020-08-11},
  abstract = {Context: Refactoring is a technique for improving the internal structure of software systems. It has a solid theoretical background while being used in development practice also. However, we lack empirical research results on the real effect of code refactoring and its application.},
  file = {/home/enrico/Zotero/storage/5QWS3Q9K/Hegedűs et al. - 2018 - Empirical evaluation of software maintainability b.pdf},
  langid = {english}
}

@article{hegedus_empirical_2018-1,
  title = {Empirical Evaluation of Software Maintainability Based on a Manually Validated Refactoring Dataset},
  author = {Hegedűs, Péter and Kádár, István and Ferenc, Rudolf and Gyimóthy, Tibor},
  date = {2018-03},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  volume = {95},
  pages = {313--327},
  issn = {09505849},
  doi = {10.1016/j.infsof.2017.11.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584916303561},
  urldate = {2020-08-11},
  abstract = {Objective: This paper presents a manually validated subset of a previously published dataset containing the refactorings extracted by the RefFinder tool, code metrics, and maintainability of 7 open-source systems. We found that RefFinder had around 27\% overall average precision on the subject systems, thus our manually validated subset has substantial added value. Using the dataset, we studied several aspects of the refactored and non-refactored source code elements (classes and methods), like the differences in their maintainability and source code metrics.
Method: We divided the source code elements into a group containing the refactored elements and a group with non-refactored elements. We analyzed the elements’ characteristics in these groups using correlation analysis, Mann–Whitney U test and effect size measures.
Results: Source code elements subjected to refactorings had significantly lower maintainability than elements not affected by refactorings. Moreover, refactored elements had significantly higher size related metrics, complexity, and coupling. Also these metrics changed more significantly in the refactored elements. The results are mostly in line with our previous findings on the not validated dataset, with the difference that clone metrics had no strong connection with refactoring.
Conclusions: Compared to the preliminary analysis using a not validated dataset, the manually validated dataset led to more significant results, which suggests that developers find targets for refactorings based on some internal quality properties of the source code, like their size, complexity or coupling, but not clone related metrics as reported in our previous studies. They do not just use these properties for identifying targets, but also control them with refactorings.},
  file = {/home/enrico/Zotero/storage/TWWNHWD3/Hegedűs et al. - 2018 - Empirical evaluation of software maintainability b.pdf},
  langid = {english}
}

@inproceedings{hellendoorn_are_2017,
  title = {Are Deep Neural Networks the Best Choice for Modeling Source Code?},
  booktitle = {Proceedings of the 2017 11th {{Joint Meeting}} on {{Foundations}} of {{Software Engineering}}  - {{ESEC}}/{{FSE}} 2017},
  author = {Hellendoorn, Vincent J. and Devanbu, Premkumar},
  date = {2017},
  pages = {763--773},
  publisher = {{ACM Press}},
  location = {{Paderborn, Germany}},
  doi = {10.1145/3106237.3106290},
  url = {http://dl.acm.org/citation.cfm?doid=3106237.3106290},
  urldate = {2020-08-02},
  abstract = {Current statistical language modeling techniques, including deeplearning based models, have proven to be quite effective for source code. We argue here that the special properties of source code can be exploited for further improvements. In this work, we enhance established language modeling approaches to handle the special challenges of modeling source code, such as: frequent changes, larger, changing vocabularies, deeply nested scopes, etc. We present a fast, nested language modeling toolkit specifically designed for software, with the ability to add \& remove text, and mix \& swap out many models. Specifically, we improve upon prior cache-modeling work and present a model with a much more expansive, multi-level notion of locality that we show to be well-suited for modeling software. We present results on varying corpora in comparison with traditional N -gram, as well as RNN, and LSTM deep-learning language models, and release all our source code for public use. Our evaluations suggest that carefully adapting N -gram models for source code can yield performance that surpasses even RNN and LSTM based deep-learning models.},
  eventtitle = {The 2017 11th {{Joint Meeting}}},
  file = {/home/enrico/Zotero/storage/LY75RLM3/Hellendoorn und Devanbu - 2017 - Are deep neural networks the best choice for model.pdf},
  isbn = {978-1-4503-5105-8},
  langid = {english}
}

@article{hidasi_session-based_2015,
  title = {Session-{{Based Recommendations}} with {{Recurrent Neural Networks}}},
  author = {Hidasi, Balázs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos},
  date = {2015-11-21},
  url = {http://arxiv.org/abs/1511.06939},
  urldate = {2016-02-10},
  abstract = {We apply recurrent neural networks (RNN) on a new domain, namely recommendation system. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches.},
  archivePrefix = {arXiv},
  eprint = {1511.06939},
  eprinttype = {arxiv},
  keywords = {_tablet,Computer Science - Information Retrieval,Computer Science - Learning,Computer Science - Neural and Evolutionary Computing}
}

@inproceedings{hindle_naturalness_2012,
  title = {On the {{Naturalness}} of {{Software}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Software Engineering}}},
  author = {Hindle, Abram and Barr, Earl T. and Su, Zhendong and Gabel, Mark and Devanbu, Premkumar},
  date = {2012},
  pages = {837--847},
  publisher = {{IEEE Press}},
  url = {http://dl.acm.org/citation.cfm?id=2337223.2337322},
  urldate = {2015-12-17},
  abstract = {Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal success of statistical approaches to speech recognition, natural language translation, question-answering, and text mining and comprehension. We begin with the conjecture that most software is also natural, in the sense that it is created by humans at work, with all the attendant constraints and limitations—and thus, like natural language, it is also likely to be repetitive and predictable. We then proceed to ask whether a) code can be usefully modeled by statistical language models and b) such models can be leveraged to support software engineers. Using the widely adopted n-gram model, we provide empirical evidence supportive of a positive answer to both these questions. We show that code is also very repetitive, and in fact even more so than natural languages. As an example use of the model, we have developed a simple code completion engine for Java that, despite its simplicity, already improves Eclipse's completion capability. We conclude the paper by laying out a vision for future research in this area.},
  isbn = {978-1-4673-1067-3},
  keywords = {_tablet},
  series = {{{ICSE}} '12},
  venue = {Piscataway, NJ, USA}
}

@unpublished{hoare_null_2009,
  title = {Null {{References}}: {{The Billion Dollar Mistake}}},
  author = {Hoare, Tony},
  date = {2009-03-13},
  url = {https://qconlondon.com/london-2009/qconlondon.com/london-2009/speaker/Tony+Hoare.html},
  eventtitle = {{{QCon}}},
  type = {Presentation},
  venue = {{London, UK}}
}

@online{hoare_tony_nodate,
  title = {Tony {{Hoare Billion Dollar Mistake}}},
  author = {Hoare, Tony},
  url = {https://qconlondon.com/london-2009/qconlondon.com/london-2009/speaker/Tony+Hoare.html},
  urldate = {2020-08-08},
  file = {/home/enrico/Zotero/storage/DTNT5VZB/Tony+Hoare.html}
}

@inproceedings{holmes_using_2005,
  title = {Using {{Structural Context}} to {{Recommend Source Code Examples}}},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Software Engineering}}},
  author = {Holmes, Reid and Murphy, Gail C.},
  date = {2005},
  pages = {117--125},
  publisher = {{ACM}},
  doi = {10.1145/1062455.1062491},
  url = {http://doi.acm.org/10.1145/1062455.1062491},
  urldate = {2015-12-07},
  abstract = {When coding to a framework, developers often become stuck, unsure of which class to subclass, which objects to instantiate and which methods to call. Example code that demonstrates the use of the framework can help developers make progress on their task. In this paper, we describe an approach for locating relevant code in an example repository that is based on heuristically matching the structure of the code under development to the example code. Our tool improves on existing approaches in two ways. First, the structural context needed to query the repository is extracted automatically from the code, freeing the developer from learning a query language or from writing their code in a particular style. Second, the repository can be generated easily from existing applications. We demonstrate the utility of this approach by reporting on a case study involving two subjects completing four programming tasks within the Eclipse integrated development environment framework.},
  isbn = {1-58113-963-2},
  keywords = {_tablet,development environment framework,examples,recommender,software structure},
  series = {{{ICSE}} '05},
  venue = {New York, NY, USA}
}

@software{iedmrc_galois-autocompletergalois-autocompleter_2019,
  title = {Galois-{{Autocompleter}}/{{Galois}}-{{Autocompleter}}},
  author = {{iedmrc}},
  date = {2019-08},
  url = {https://github.com/galois-autocompleter/galois-autocompleter},
  urldate = {2020-07-30},
  abstract = {Galois is an auto code completer for code editors (or any text editor) based on OpenAI GPT-2.},
  keywords = {code-completion,deep-learning,gpt-2,nlp},
  organization = {{Galois Autocompleter}}
}

@article{ismail_responses_1978,
  title = {Responses of {{Anopheles}} Minimus to {{DDT}} Residual Spraying in a Cleared Forested Foothill Area in Central {{Thailand}}},
  author = {Ismail, I. A. and Phinichpongse, S. and Boonrasri, P.},
  date = {1978-03},
  journaltitle = {Acta Tropica},
  shortjournal = {Acta Trop.},
  volume = {35},
  pages = {69--82},
  issn = {0001-706X},
  abstract = {Anopheles balabacensis balabacensis and Anopheles minimus are the main malaria vectors in Thailand. In a cleared forested foothill area in the central part of the country A. minimus was the most prevalent anopheline species found, only 6 specimens of A. b. balabacensis being collected over a 3-year period. Cattle were scarce in the area, tractors being largely used for working in the fields. This situation contributed to high man-vector contact. A minimus occurred throughout the year, with a major peak of density in the dry cool season and a smaller peak in the wet season. The contact of A. minimus with man was much higher outdoors than indoors, and studies showed the species to be an early biter, especially in the dry season, thus increasing the chance of man-vector contact. DDT spraying appeared to reduce considerably the estimated vectorial capacities, however, this effect was not maintained and malaria transmission was not interrupted. Trials with supplementary or alternative attack measures are therefore indicated in this particular ecological situation.},
  eprint = {25000},
  eprinttype = {pmid},
  keywords = {Animals,Anopheles,DDT,Disease Vectors,Malaria,Thailand},
  langid = {english},
  number = {1}
}

@report{iso_central_secretary_systems_2014,
  title = {Systems and Software Engineering — {{Systems}} and Software {{Quality Requirements}} and {{Evaluation}} ({{SQuaRE}}) — {{Guide}} to {{SQuaRE}}},
  shorttitle = {{{ISO}}/{{IEC}} 25000:2014},
  author = {ISO Central Secretary},
  date = {2014},
  institution = {{International Organization for Standardization}},
  location = {{Geneva, CH}},
  url = {https://www.iso.org/standard/64764.html},
  langid = {english},
  number = {ISO/IEC 25000:2014},
  type = {Standard}
}

@inproceedings{jacobellis_cookbook_2014,
  title = {Cookbook: {{In Situ Code Completion Using Edit Recipes Learned}} from {{Examples}}},
  shorttitle = {Cookbook},
  booktitle = {Companion {{Proceedings}} of the 36th {{International Conference}} on {{Software Engineering}}},
  author = {Jacobellis, John and Meng, Na and Kim, Miryung},
  date = {2014},
  pages = {584--587},
  publisher = {{ACM}},
  url = {http://dl.acm.org/citation.cfm?id=2591076},
  urldate = {2016-06-24},
  keywords = {_tablet}
}

@article{karampatsis_big_2020,
  title = {Big {{Code}} != {{Big Vocabulary}}: {{Open}}-{{Vocabulary Models}} for {{Source Code}}},
  shorttitle = {Big {{Code}} != {{Big Vocabulary}}},
  author = {Karampatsis, Rafael-Michael and Babii, Hlib and Robbes, Romain and Sutton, Charles and Janes, Andrea},
  date = {2020-03-17},
  doi = {10.1145/3377811.3380342},
  url = {http://arxiv.org/abs/2003.07914},
  urldate = {2020-06-11},
  abstract = {Statistical language modeling techniques have successfully been applied to large source code corpora, yielding a variety of new software development tools, such as tools for code suggestion, improving readability, and API migration. A major issue with these techniques is that code introduces new vocabulary at a far higher rate than natural language, as new identifier names proliferate. Both large vocabularies and out-of-vocabulary issues severely affect Neural Language Models (NLMs) of source code, degrading their performance and rendering them unable to scale. In this paper, we address this issue by: 1) studying how various modelling choices impact the resulting vocabulary on a large-scale corpus of 13,362 projects; 2) presenting an open vocabulary source code NLM that can scale to such a corpus, 100 times larger than in previous work; and 3) showing that such models outperform the state of the art on three distinct code corpora (Java, C, Python). To our knowledge, these are the largest NLMs for code that have been reported. All datasets, code, and trained models used in this work are publicly available.},
  archivePrefix = {arXiv},
  eprint = {2003.07914},
  eprinttype = {arxiv},
  keywords = {Computer Science - Software Engineering}
}

@article{kim_code_2020,
  title = {Code {{Prediction}} by {{Feeding Trees}} to {{Transformers}}},
  author = {Kim, Seohyun and Zhao, Jinman and Tian, Yuchi and Chandra, Satish},
  date = {2020-05-21},
  url = {http://arxiv.org/abs/2003.13848},
  urldate = {2020-06-11},
  abstract = {We advance the state-of-the-art in the accuracy of code prediction (next token prediction) used in autocomplete systems. First, we report that using the recently proposed Transformer architecture even out-of-the-box outperforms previous neural and non-neural systems for code prediction. We then show that by making the Transformer architecture aware of the syntactic structure of code, we further increase the margin by which a Transformer-based system outperforms previous state-of-the-art systems. With this, it outperforms the accuracy of an RNN-based system by 37.0\textbackslash textbackslash\%, the decision-tree based Deep3 system by 29.7\textbackslash textbackslash\%, and an adaptation of Code2Seq for code prediction by 30.0\textbackslash textbackslash\%. These are significant margins. We present in the paper several ways of communicating the code structure to the Transformer, which is fundamentally built for processing sequence data. The most effective of these is when we enrich the self-attention mechanism of the Transformer. We enable the mechanism to learn weights—that is, how much to focus on each preceding token in the input—not only on the basis of a token's value, but also on the basis of the spatial relationships, as in their positions in the abstract syntax tree, between each pair of tokens. We provide a comprehensive experimental evaluation of our proposal, along with alternative design choices, on a standard Python dataset, as well as on a company internal Python corpus. Our code and data preparation pipeline are available in open source.},
  archivePrefix = {arXiv},
  eprint = {2003.13848},
  eprinttype = {arxiv},
  keywords = {Computer Science - Software Engineering}
}

@article{kim_code_2020-1,
  title = {Code {{Prediction}} by {{Feeding Trees}} to {{Transformers}}},
  author = {Kim, Seohyun and Zhao, Jinman and Tian, Yuchi and Chandra, Satish},
  date = {2020-07-02},
  url = {http://arxiv.org/abs/2003.13848},
  urldate = {2020-08-02},
  abstract = {We advance the state-of-the-art in the accuracy of code prediction (next token prediction) used in autocomplete systems. First, we report that using the recently proposed Transformer architecture even out-of-the-box outperforms previous neural and non-neural systems for code prediction. We then show that by making the Transformer architecture aware of the syntactic structure of code, we further increase the margin by which a Transformer-based system outperforms previous systems. With this, it outperforms the accuracy of an RNN-based system (similar to Hellendoorn et al. 2018) by 18.3\textbackslash\%, the Deep3 system (Raychev et al 2016) by 14.1\textbackslash\%, and an adaptation of Code2Seq (Alon et al., 2018) for code prediction by 14.4\textbackslash\%. We present in the paper several ways of communicating the code structure to the Transformer, which is fundamentally built for processing sequence data. We provide a comprehensive experimental evaluation of our proposal, along with alternative design choices, on a standard Python dataset, as well as on a Facebook internal Python corpus. Our code and data preparation pipeline will be available in open source.},
  archivePrefix = {arXiv},
  eprint = {2003.13848},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/I3CPGWHP/Kim et al. - 2020 - Code Prediction by Feeding Trees to Transformers.pdf},
  keywords = {Computer Science - Software Engineering},
  langid = {english},
  primaryClass = {cs}
}

@article{kim_code_2020-2,
  title = {Code {{Prediction}} by {{Feeding Trees}} to {{Transformers}}},
  author = {Kim, Seohyun and Zhao, Jinman and Tian, Yuchi and Chandra, Satish},
  date = {2020-07-02},
  url = {http://arxiv.org/abs/2003.13848},
  urldate = {2020-08-02},
  abstract = {We advance the state-of-the-art in the accuracy of code prediction (next token prediction) used in autocomplete systems. First, we report that using the recently proposed Transformer architecture even out-of-the-box outperforms previous neural and non-neural systems for code prediction. We then show that by making the Transformer architecture aware of the syntactic structure of code, we further increase the margin by which a Transformer-based system outperforms previous systems. With this, it outperforms the accuracy of an RNN-based system (similar to Hellendoorn et al. 2018) by 18.3\textbackslash\%, the Deep3 system (Raychev et al 2016) by 14.1\textbackslash\%, and an adaptation of Code2Seq (Alon et al., 2018) for code prediction by 14.4\textbackslash\%. We present in the paper several ways of communicating the code structure to the Transformer, which is fundamentally built for processing sequence data. We provide a comprehensive experimental evaluation of our proposal, along with alternative design choices, on a standard Python dataset, as well as on a Facebook internal Python corpus. Our code and data preparation pipeline will be available in open source.},
  archivePrefix = {arXiv},
  eprint = {2003.13848},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/Y8P66MJV/Kim et al. - 2020 - Code Prediction by Feeding Trees to Transformers.pdf},
  keywords = {Computer Science - Software Engineering,Encoding,gpt-2},
  langid = {english},
  primaryClass = {cs}
}

@article{laradji_software_2015,
  title = {Software Defect Prediction Using Ensemble Learning on Selected Features},
  author = {Laradji, Issam H. and Alshayeb, Mohammad and Ghouti, Lahouari},
  date = {2015-02},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  volume = {58},
  pages = {388--402},
  issn = {09505849},
  doi = {10.1016/j.infsof.2014.07.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584914001591},
  urldate = {2020-08-11},
  abstract = {Objective: The objectives of this paper are to demonstrate the positive effects of combining feature selection and ensemble learning on the performance of defect classification. Along with efficient feature selection, a new two-variant (with and without feature selection) ensemble learning algorithm is proposed to provide robustness to both data imbalance and feature redundancy.
Method: We carefully combine selected ensemble learning models with efficient feature selection to address these issues and mitigate their effects on the defect classification performance.
Results: Forward selection showed that only few features contribute to high area under the receiver-operating curve (AUC). On the tested datasets, greedy forward selection (GFS) method outperformed other feature selection techniques such as Pearson’s correlation. This suggests that features are highly unstable. However, ensemble learners like random forests and the proposed algorithm, average probability ensemble (APE), are not as affected by poor features as in the case of weighted support vector machines (W-SVMs). Moreover, the APE model combined with greedy forward selection (enhanced APE) achieved AUC values of approximately 1.0 for the NASA datasets: PC2, PC4, and MC1.
Conclusion: This paper shows that features of a software dataset must be carefully selected for accurate classification of defective components. Furthermore, tackling the software data issues, mentioned above, with the proposed combined learning model resulted in remarkable classification performance paving the way for successful quality control.},
  file = {/home/enrico/Zotero/storage/YIRMHG5X/Laradji et al. - 2015 - Software defect prediction using ensemble learning.pdf},
  langid = {english}
}

@article{latte_clean_2019,
  title = {Clean {{Code}}: {{On}} the {{Use}} of {{Practices}} and {{Tools}} to {{Produce Maintainable Code}} for {{Long}}-{{Living Software}}},
  author = {Latte, Bjorn and Henning, Soren and Wojcieszak, Maik},
  date = {2019},
  journaltitle = {Living Systems},
  pages = {4},
  abstract = {Maintaining a long-living software system is substantially related to the quality of the code the system is built from. In this experience report we describe how a set of practices and tools has been established and used on the early stages of a project. The approach is based on Clean Code and the use of well known static code analysis tools. The tools and practices have been used with an immediate effect of having cleaner code that is easier to understand in the long term. Additional attention is given to the cultural aspect that is involved in reaching a mindset that will allow to set and uphold code quality standards. Reaching a common understanding is a team effort that requires ”leaving one’s comfort zone“. Finding common ground can significantly decide about failure or success in creating maintainable code.},
  file = {/home/enrico/Zotero/storage/IFT6DKFE/Latte et al. - Clean Code On the Use of Practices and Tools to P.pdf},
  langid = {english}
}

@inproceedings{lee_temporal_2013,
  title = {Temporal {{Code Completion}} and {{Navigation}}},
  booktitle = {Proceedings of the 2013 {{International Conference}} on {{Software Engineering}}},
  author = {Lee, Yun Young and Harwell, Sam and Khurshid, Sarfraz and Marinov, Darko},
  date = {2013},
  pages = {1181--1184},
  publisher = {{IEEE Press}},
  url = {http://dl.acm.org/citation.cfm?id=2486788.2486956},
  urldate = {2015-12-07},
  abstract = {Modern IDEs make many software engineering tasks easier by automating functionality such as code completion and navigation. However, this functionality operates on one version of the code at a time. We envision a new approach that makes code completion and navigation aware of code evolution and enables them to operate on multiple versions at a time, without having to manually switch across these versions. We illustrate our approach on several example scenarios. We also describe a prototype Eclipse plugin that embodies our approach for code completion and navigation for Java code. We believe our approach opens a new line of research that adds a novel, temporal dimension for treating code in IDEs in the context of tasks that previously required manual switching across different code versions.},
  isbn = {978-1-4673-3076-3},
  keywords = {_tablet},
  series = {{{ICSE}} '13},
  venue = {Piscataway, NJ, USA}
}

@inproceedings{li_code_2018,
  title = {Code {{Completion}} with {{Neural Attention}} and {{Pointer Networks}}},
  booktitle = {Proceedings of the {{Twenty}}-{{Seventh International Joint Conference}} on {{Artificial Intelligence}}, {{IJCAI}}-18},
  author = {Li, Jian and Wang, Yue and Lyu, Michael R. and King, Irwin},
  date = {2018-07},
  pages = {4159--4165},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  doi = {10.24963/ijcai.2018/578},
  url = {https://doi.org/10.24963/ijcai.2018/578}
}

@article{li_code_2018-1,
  title = {Code {{Completion}} with {{Neural Attention}} and {{Pointer Networks}}},
  author = {Li, Jian and Wang, Yue and Lyu, Michael R. and King, Irwin},
  date = {2018-07},
  journaltitle = {Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence},
  pages = {4159--4165},
  doi = {10.24963/ijcai.2018/578},
  url = {http://arxiv.org/abs/1711.09573},
  urldate = {2020-08-02},
  abstract = {Intelligent code completion has become an essential research task to accelerate modern software development. To facilitate effective code completion for dynamically-typed programming languages, we apply neural language models by learning from large codebases, and develop a tailored attention mechanism for code completion. However, standard neural language models even with attention mechanism cannot correctly predict the outof-vocabulary (OoV) words that restrict the code completion performance. In this paper, inspired by the prevalence of locally repeated terms in program source code, and the recently proposed pointer copy mechanism, we propose a pointer mixture network for better predicting OoV words in code completion. Based on the context, the pointer mixture network learns to either generate a withinvocabulary word through an RNN component, or regenerate an OoV word from local context through a pointer component. Experiments on two benchmarked datasets demonstrate the effectiveness of our attention mechanism and pointer mixture network on the code completion task.},
  archivePrefix = {arXiv},
  eprint = {1711.09573},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/WLLNLQEF/Li et al. - 2018 - Code Completion with Neural Attention and Pointer .pdf},
  keywords = {Computer Science - Computation and Language,Computer Science - Software Engineering},
  langid = {english}
}

@inproceedings{li_software_2017,
  title = {Software {{Defect Prediction}} via {{Convolutional Neural Network}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security}} ({{QRS}})},
  author = {Li, Jian and He, Pinjia and Zhu, Jieming and Lyu, Michael R.},
  date = {2017-07},
  pages = {318--328},
  issn = {null},
  doi = {10.1109/QRS.2017.42},
  abstract = {To improve software reliability, software defect prediction is utilized to assist developers in finding potential bugs and allocating their testing efforts. Traditional defect prediction studies mainly focus on designing hand-crafted features, which are input into machine learning classifiers to identify defective code. However, these hand-crafted features often fail to capture the semantic and structural information of programs. Such information is important in modeling program functionality and can lead to more accurate defect prediction. In this paper, we propose a framework called Defect Prediction via Convolutional Neural Network (DP-CNN), which leverages deep learning for effective feature generation. Specifically, based on the programs' Abstract Syntax Trees (ASTs), we first extract token vectors, which are then encoded as numerical vectors via mapping and word embedding. We feed the numerical vectors into Convolutional Neural Network to automatically learn semantic and structural features of programs. After that, we combine the learned features with traditional hand-crafted features, for accurate software defect prediction. We evaluate our method on seven open source projects in terms of F-measure in defect prediction. The experimental results show that in average, DP-CNN improves the state-of-the-art method by 12\%.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security}} ({{QRS}})},
  keywords = {abstract syntax trees,AST,CNN,Convolutional codes,deep learning,defect prediction via convolutional neural network,DP-CNN,Feature extraction,learning (artificial intelligence),Machine learning,machine learning classifiers,neural nets,Neural networks,open source projects,Semantics,Software,software defect prediction,software reliability,Software reliability}
}

@article{lika_facing_2014,
  title = {Facing the {{Cold Start Problem}} in {{Recommender Systems}}},
  author = {Lika, Blerina and Kolomvatsos, Kostas and Hadjiefthymiades, Stathes},
  date = {2014-03},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {41},
  pages = {2065--2073},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2013.09.005},
  url = {http://www.sciencedirect.com/science/article/pii/S0957417413007240},
  urldate = {2016-02-08},
  abstract = {A recommender system (RS) aims to provide personalized recommendations to users for specific items (e.g., music, books). Popular techniques involve content-based (CB) models and collaborative filtering (CF) approaches. In this paper, we deal with a very important problem in RSs: The cold start problem. This problem is related to recommendations for novel users or new items. In case of new users, the system does not have information about their preferences in order to make recommendations. We propose a model where widely known classification algorithms in combination with similarity techniques and prediction mechanisms provide the necessary means for retrieving recommendations. The proposed approach incorporates classification methods in a pure CF system while the use of demographic data help for the identification of other users with similar behavior. Our experiments show the performance of the proposed system through a large number of experiments. We adopt the widely known dataset provided by the GroupLens research group. We reveal the advantages of the proposed solution by providing satisfactory numerical results in different experimental scenarios.},
  issue = {4, Part 2},
  keywords = {Cold start problem,recommender systems}
}

@article{liu_neural_2017,
  title = {Neural {{Code Completion}}},
  author = {Liu, Chang and Wang, Xin and Shin, Richard and Gonzalez, Joseph E and Song, Dawn},
  date = {2017},
  pages = {14},
  abstract = {Code completion, an essential part of modern software development, yet can be challenging for dynamically typed programming languages. In this paper we explore the use of neural network techniques to automatically learn code completion from a large corpus of dynamically typed JavaScript code. We show different neural networks that leverage not only token level information but also structural information, and evaluate their performance on different prediction tasks. We demonstrate that our models can outperform the state-of-the-art approach, which is based on decision tree techniques, on both next non-terminal and next terminal prediction tasks by 3.8 points and 0.5 points respectively. We believe that neural network techniques can play a transformative role in helping software developers manage the growing complexity of software systems, and we see this work as a first step in that direction.}
}

@inproceedings{liu_nomen_2016,
  title = {Nomen {{Est Omen}}: {{Exploring}} and {{Exploiting Similarities Between Argument}} and {{Parameter Names}}},
  shorttitle = {Nomen {{Est Omen}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Software Engineering}}},
  author = {Liu, Hui and Liu, Qiurong and Staicu, Cristian-Alexandru and Pradel, Michael and Luo, Yue},
  date = {2016},
  pages = {1063--1073},
  publisher = {{ACM}},
  doi = {10.1145/2884781.2884841},
  url = {http://doi.acm.org/10.1145/2884781.2884841},
  urldate = {2016-06-19},
  abstract = {Programmer-provided identifier names convey information about the semantics of a program. This information can complement traditional program analyses in various software engineering tasks, such as bug finding, code completion, and documentation. Even though identifier names appear to be a rich source of information, little is known about their properties and their potential usefulness. This paper presents an empirical study of the lexical similarity between arguments and parameters of methods, which is one prominent situation where names can provide otherwise missing information. The study involves 60 real-world Java programs. We find that, for most arguments, the similarity is either very high or very low, and that short and generic names often cause low similarities. Furthermore, we show that inferring a set of low-similarity parameter names from one set of programs allows for pruning such names in another set of programs. Finally, the study shows that many arguments are more similar to the corresponding parameter than any alternative argument available in the call site's scope. As applications of our findings, we present an anomaly detection technique that identifies 144 renaming opportunities and incorrect arguments in 14 programs, and a code recommendation system that suggests correct arguments with a precision of 83\%.},
  isbn = {978-1-4503-3900-1},
  keywords = {_tablet,empirical study,identifier names,method arguments,name-based program analysis,static analysis},
  series = {{{ICSE}} '16},
  venue = {New York, NY, USA}
}

@article{liu_self-attentional_2019,
  title = {A {{Self}}-{{Attentional Neural Architecture}} for {{Code Completion}} with {{Multi}}-{{Task Learning}}},
  author = {Liu, Fang and Li, Ge and Wei, Bolin and Xia, Xin and Li, Ming and Fu, Zhiyi and Jin, Zhi},
  date = {2019},
  journaltitle = {ArXiv},
  volume = {abs/1909.06983},
  url = {https://arxiv.org/abs/1909.06983v1},
  abstract = {Code completion, one of the most useful features in the integrated development environments, can accelerate software development by suggesting the libraries, APIs, method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program's representation; b) In programs, the semantic relationships can be very long, existing LSTM based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. In this paper, we present a novel method that introduces the hierarchical structural information into the representation of programs by considering the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we apply Transformer-XL network as the base language model. Besides, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly, where knowledge acquired from one task could be beneficial to another task. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.},
  archivePrefix = {arXiv},
  eprint = {1909.06983},
  eprinttype = {arxiv},
  keywords = {Emoticon,Experiment,Integrated development environment,Language model,Library (computing),Long short-term memory,Multi-task learning,Real-time clock,Real-time computing,Software development,Software repository,Transformer,Tree (data structure)}
}

@article{liu_self-attentional_2020,
  title = {A {{Self}}-{{Attentional Neural Architecture}} for {{Code Completion}} with {{Multi}}-{{Task Learning}}},
  author = {Liu, Fang and Li, Ge and Wei, Bolin and Xia, Xin and Fu, Zhiyi and Jin, Zhi},
  date = {2020-06-26},
  url = {http://arxiv.org/abs/1909.06983},
  urldate = {2020-07-01},
  abstract = {Code completion, one of the most useful features in the Integrated Development Environments (IDEs), can accelerate software development by suggesting the libraries, APIs, and method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program's representation; b) In programs, the semantic relationships can be very long. Existing recurrent neural networks based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. To address these challenges, in this paper, we propose a self-attentional neural architecture for code completion with multi-task learning. To utilize the hierarchical structural information of the programs, we present a novel method that considers the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we adopt a self-attentional architecture based network as the base language model. To enable the knowledge sharing between related tasks, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.},
  archivePrefix = {arXiv},
  eprint = {1909.06983},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/AF4RKSW3/Liu et al. - 2020 - A Self-Attentional Neural Architecture for Code Co.pdf},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering}
}

@article{liu_self-attentional_2020-1,
  title = {A {{Self}}-{{Attentional Neural Architecture}} for {{Code Completion}} with {{Multi}}-{{Task Learning}}},
  author = {Liu, Fang and Li, Ge and Wei, Bolin and Xia, Xin and Fu, Zhiyi and Jin, Zhi},
  date = {2020-06-26},
  url = {http://arxiv.org/abs/1909.06983},
  urldate = {2020-08-02},
  abstract = {Code completion, one of the most useful features in the Integrated Development Environments (IDEs), can accelerate software development by suggesting the libraries, APIs, and method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program’s representation; b) In programs, the semantic relationships can be very long. Existing recurrent neural networks based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. To address these challenges, in this paper, we propose a selfattentional neural architecture for code completion with multi-task learning. To utilize the hierarchical structural information of the programs, we present a novel method that considers the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we adopt a self-attentional architecture based network as the base language model. To enable the knowledge sharing between related tasks, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.},
  archivePrefix = {arXiv},
  eprint = {1909.06983},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/5RXXFIKM/Liu et al. - 2020 - A Self-Attentional Neural Architecture for Code Co.pdf},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  langid = {english},
  primaryClass = {cs}
}

@inproceedings{lozano_mendel_2011,
  title = {Mendel: {{Source Code Recommendation Based}} on a {{Genetic Metaphor}}},
  shorttitle = {Mendel},
  booktitle = {Proceedings of the 2011 26th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}},
  author = {Lozano, Angela and Kellens, Andy and Mens, Kim},
  date = {2011},
  pages = {384--387},
  publisher = {{IEEE Computer Society}},
  doi = {10.1109/ASE.2011.6100078},
  url = {http://dx.doi.org/10.1109/ASE.2011.6100078},
  urldate = {2015-12-07},
  abstract = {When evolving software systems, developers spend a considerable amount of time understanding existing source code. To successfully implement new or alter existing behavior, developers need to answer questions such as: "Which types and methods can I use to solve this task?" or "Should my implementation follow particular naming or structural conventions?". In this paper we present Mendel, a source code recommendation tool that aids developers in answering such questions. Based on the entity the developer currently browses, the tool employs a genetics-inspired metaphor to analyze source-code entities related to the current working context and provides its user with a number of recommended properties (naming conventions, used types, invoked messages, etc.) that the source code entity currently being worked on should exhibit. An initial validation of Mendel seems to confirm the potential of our approach.},
  isbn = {978-1-4577-1638-6},
  keywords = {_tablet},
  series = {{{ASE}} '11},
  venue = {Washington, DC, USA}
}

@article{luan_aroma_2019,
  title = {Aroma: {{Code Recommendation}} via {{Structural Code Search}}},
  shorttitle = {Aroma},
  author = {Luan, Sifei and Yang, Di and Barnaby, Celeste and Sen, Koushik and Chandra, Satish},
  date = {2019-10-10},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {3},
  pages = {1--28},
  issn = {24751421},
  doi = {10.1145/3360578},
  url = {http://arxiv.org/abs/1812.01158},
  urldate = {2019-11-09},
  abstract = {Programmers often write code that has similarity to existing code written somewhere. A tool that could help programmers to search such similar code would be immensely useful. Such a tool could help programmers to extend partially written code snippets to completely implement necessary functionality, help to discover extensions to the partial code which are commonly included by other programmers, help to cross-check against similar code written by other programmers, or help to add extra code which would fix common mistakes and errors. We propose Aroma, a tool and technique for code recommendation via structural code search. Aroma indexes a huge code corpus including thousands of open-source projects, takes a partial code snippet as input, searches the corpus for method bodies containing the partial code snippet, and clusters and intersects the results of the search to recommend a small set of succinct code snippets which both contain the query snippet and appear as part of several methods in the corpus. We evaluated Aroma on 2000 randomly selected queries created from the corpus, as well as 64 queries derived from code snippets obtained from Stack Overflow, a popular website for discussing code. We implemented Aroma for 4 different languages, and developed an IDE plugin for Aroma. Furthermore, we conducted a study where we asked 12 programmers to complete programming tasks using Aroma, and collected their feedback. Our results indicate that Aroma is capable of retrieving and recommending relevant code snippets efficiently.},
  archivePrefix = {arXiv},
  eprint = {1812.01158},
  eprinttype = {arxiv},
  issue = {OOPSLA},
  keywords = {Computer Science - Software Engineering}
}

@article{luan_aroma_2019-1,
  title = {Aroma: {{Code Recommendation}} via {{Structural Code Search}}},
  shorttitle = {Aroma},
  author = {Luan, Sifei and Yang, Di and Barnaby, Celeste and Sen, Koushik and Chandra, Satish},
  date = {2019-10-10},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {3},
  pages = {1--28},
  issn = {2475-1421, 2475-1421},
  doi = {10.1145/3360578},
  url = {http://arxiv.org/abs/1812.01158},
  urldate = {2020-08-02},
  abstract = {Programmers often write code that has similarity to existing code written somewhere. A tool that could help programmers to search such similar code would be immensely useful. Such a tool could help programmers to extend partially written code snippets to completely implement necessary functionality, help to discover extensions to the partial code which are commonly included by other programmers, help to cross-check against similar code written by other programmers, or help to add extra code which would fix common mistakes and errors. We propose Aroma, a tool and technique for code recommendation via structural code search. Aroma indexes a huge code corpus including thousands of open-source projects, takes a partial code snippet as input, searches the corpus for method bodies containing the partial code snippet, and clusters and intersects the results of the search to recommend a small set of succinct code snippets which both contain the query snippet and appear as part of several methods in the corpus. We evaluated Aroma on 2000 randomly selected queries created from the corpus, as well as 64 queries derived from code snippets obtained from Stack Overflow, a popular website for discussing code. We implemented Aroma for 4 different languages, and developed an IDE plugin for Aroma. Furthermore, we conducted a study where we asked 12 programmers to complete programming tasks using Aroma, and collected their feedback. Our results indicate that Aroma is capable of retrieving and recommending relevant code snippets efficiently. CCS Concepts: • Information systems → Near-duplicate and plagiarism detection; • Software and its engineering → Development frameworks and environments; Software post-development issues.},
  archivePrefix = {arXiv},
  eprint = {1812.01158},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/LYSLGYDG/Luan et al. - 2019 - Aroma Code Recommendation via Structural Code Sea.pdf},
  issue = {OOPSLA},
  keywords = {Computer Science - Software Engineering},
  langid = {english}
}

@inproceedings{lv_apisynth_2014,
  title = {{{APISynth}}: {{A New Graph}}-{{Based API Recommender System}}},
  shorttitle = {{{APISynth}}},
  booktitle = {Companion {{Proceedings}} of the 36th {{International Conference}} on {{Software Engineering}}},
  author = {Lv, Chen and Jiang, Wei and Liu, Yue and Hu, Songlin},
  date = {2014},
  pages = {596--597},
  publisher = {{ACM}},
  doi = {10.1145/2591062.2591133},
  url = {http://doi.acm.org/10.1145/2591062.2591133},
  urldate = {2015-12-07},
  abstract = {Current API recommendation tools yield either good recall ratio or good precision, but not both. A tool named APISynth is proposed in this paper by utilizing a new graph based approach. Preliminary evaluation demonstrates that APISynth wins over the state of the art with respect to both the two criteria.},
  isbn = {978-1-4503-2768-8},
  keywords = {_tablet,API Recommender,Code Assistant,code reuse},
  series = {{{ICSE Companion}} 2014},
  venue = {New York, NY, USA}
}

@inproceedings{malheiros_source_2012,
  title = {A {{Source Code Recommender System}} to {{Support Newcomers}}},
  booktitle = {Computer {{Software}} and {{Applications Conference}} ({{COMPSAC}}), 2012 {{IEEE}} 36th {{Annual}}},
  author = {Malheiros, Y. and Moraes, A. and Trindade, C. and Meira, S.},
  date = {2012-07},
  pages = {19--24},
  doi = {10.1109/COMPSAC.2012.11},
  abstract = {Newcomers in a software development project often need assistance to complete their first tasks. Then a mentor, an experienced member of the team, usually teaches the newcomers what they need to complete their tasks. But, to allocate an experienced member of a team to teach a newcomer during a long time is neither always possible nor desirable, because the mentor could be more helpful doing more important tasks. During the development the team interacts with a version control system, bug tracking and mailing lists, and all these tools record data creating the project memory. Recommender systems can use the project memory to help newcomers in some tasks answering their questions, thus in some cases the developers do not need a mentor. In this paper we present Mentor, a recommender system to help newcomers to solve change requests. Mentor uses the Prediction by Partial Matching (PPM) algorithm and some heuristics to analyze the change requests, and the version control data, and recommend potentially relevant source code that will help the developer in the change request solution. We did three experiments to compare the PPM algorithm with the Latent Semantic Indexing (LSI). Using PPM we achieved results for recall rate between 37\% and 66.8\%, and using LSI the results were between 20.3\% and 51.6\%.},
  eventtitle = {Computer {{Software}} and {{Applications Conference}} ({{COMPSAC}}), 2012 {{IEEE}} 36th {{Annual}}},
  keywords = {_tablet,bug tracking,configuration management,Context,Databases,Entropy,experienced team member,Indexing,information theory,Large scale integration,latent semantic indexing,LSI,mailing lists,Measurement,Mentor,newcomers,Pattern matching,PPM algorithm,prediction by partial matching algorithm,program debugging,project memory,recommender system,recommender systems,Software,software development project,software engineering,Software maintenance,source code recommender system,version control data,version control system}
}

@article{malhotra_software_2016,
  title = {Software {{Maintainability}}: {{Systematic Literature Review}} and {{Current Trends}}},
  shorttitle = {Software {{Maintainability}}},
  author = {Malhotra, Ruchika and Chug, Anuradha},
  date = {2016-10},
  journaltitle = {International Journal of Software Engineering and Knowledge Engineering},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  volume = {26},
  pages = {1221--1253},
  issn = {0218-1940, 1793-6403},
  doi = {10.1142/S0218194016500431},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0218194016500431},
  urldate = {2020-08-11},
  abstract = {Software maintenance is an expensive activity that consumes a major portion of the cost of the total project. Various activities carried out during maintenance include the addition of new features, deletion of obsolete code, correction of errors, etc. Software maintainability means the ease with which these operations can be carried out. If the maintainability can be measured in early phases of the software development, it helps in better planning and optimum resource utilization. Measurement of design properties such as coupling, cohesion, etc. in early phases of development often leads us to derive the corresponding maintainability with the help of prediction models. In this paper, we performed a systematic review of the existing studies related to software maintainability from January 1991 to October 2015. In total, 96 primary studies were identified out of which 47 studies were from journals, 36 from conference proceedings and 13 from others. All studies were compiled in structured form and analyzed through numerous perspectives such as the use of design metrics, prediction model, tools, data sources, prediction accuracy, etc. According to the review results, we found that the use of machine learning algorithms in predicting maintainability has increased since 2005. The use of evolutionary algorithms has also begun in related sub-fields since 2010. We have observed that design metrics is still the most favored option to capture the characteristics of any given software before deploying it further in prediction model for determining the corresponding software maintainability. A significant increase in the use of public dataset for making the prediction models has also been observed and in this regard two public datasets User Interface Management System (UIMS) and Quality Evaluation System (QUES) proposed by Li and Henry is quite popular among researchers. Although machine learning algorithms are still the most popular methods, however, we suggest that researchers working on software maintainability area should experiment on the use of open source datasets with hybrid algorithms. In this regard, more empirical studies are also required to be conducted on a large number of datasets so that a generalized theory could be made. The current paper will be beneficial for practitioners, researchers and developers as they can use these models and metrics for creating benchmark and standards. Findings of this extensive review would also be useful for novices in the field of software maintainability as it not only provides explicit definitions, but also lays a foundation for further research by providing a quick link to all important studies in the said field. Finally, this study also compiles current trends, emerging sub-fields and identifies various opportunities of future research in the field of software maintainability.},
  file = {/home/enrico/Zotero/storage/FDYH3FY9/Malhotra und Chug - 2016 - Software Maintainability Systematic Literature Re.pdf},
  langid = {english},
  number = {08}
}

@book{martin_clean_2009,
  title = {Clean Code: A Handbook of Agile Software Craftsmanship},
  author = {Martin, Robert C},
  date = {2009},
  publisher = {{Pearson Education}}
}

@inproceedings{mkaouer_recommendation_2014,
  title = {Recommendation {{System}} for {{Software Refactoring Using Innovization}} and {{Interactive Dynamic Optimization}}},
  booktitle = {Proceedings of the 29th {{ACM}}/{{IEEE International Conference}} on {{Automated Software Engineering}}},
  author = {Mkaouer, Mohamed Wiem and Kessentini, Marouane and Bechikh, Slim and Deb, Kalyanmoy and Ó Cinnéide, Mel},
  date = {2014},
  pages = {331--336},
  publisher = {{ACM}},
  doi = {10.1145/2642937.2642965},
  url = {http://doi.acm.org/10.1145/2642937.2642965},
  urldate = {2015-12-05},
  abstract = {We propose a novel recommendation tool for software refactoring that dynamically adapts and suggests refactorings to developers interactively based on their feedback and introduced code changes. Our approach starts by finding upfront a set of non-dominated refactoring solutions using NSGA-II to improve software quality, reduce the number of refactorings and increase semantic coherence. The generated non-dominated refactoring solutions are analyzed using our innovization component to extract some interesting common features between them. Based on this analysis, the suggested refactorings are ranked and suggested to the developer one by one. The developer can approve, modify or reject each suggested refactoring, and this feedback is used to update the ranking of the suggested refactorings. After a number of introduced code changes, a local search is performed to update and adapt the set of refactoring solutions suggested by NSGA-II. We evaluated this tool on four large open source systems and one industrial project provided by our partner. Statistical analysis of our experiments over 31 runs shows that the dynamic refactoring approach performed significantly better than three other search-based refactoring techniques, manual refactorings, and one refactoring tool not based on heuristic search.},
  isbn = {978-1-4503-3013-8},
  keywords = {_tablet,refactoring,search based software engineering,software quality},
  series = {{{ASE}} '14},
  venue = {New York, NY, USA}
}

@inproceedings{nguyen_graph-based_2012,
  title = {Graph-{{Based Pattern}}-{{Oriented}}, {{Context}}-{{Sensitive Source Code Completion}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Software Engineering}}},
  author = {Nguyen, Anh Tuan and Nguyen, Tung Thanh and Nguyen, Hoan Anh and Tamrawi, Ahmed and Nguyen, Hung Viet and Al-Kofahi, Jafar and Nguyen, Tien N.},
  date = {2012},
  pages = {69--79},
  publisher = {{IEEE Press}},
  url = {http://dl.acm.org/citation.cfm?id=2337223.2337232},
  urldate = {2015-12-04},
  abstract = {Code completion helps improve programming productivity. However, current support for code completion is limited to context-free code templates or a single method call of the variable on focus. Using libraries for development, developers often repeat API usages for certain tasks. Therefore, in this paper, we introduce GraPacc, a graph-based pattern-oriented, context-sensitive code completion approach that is based on a database of API usage patterns. GraPacc manages and represents the API usage patterns of multiple variables, methods, and control structures via graph-based models. It extracts the context-sensitive features from the code, e.g. the API elements on focus or under modification, and their relations to other elements. The features are used to search and rank the patterns that are most fitted with the current code. When a pattern is selected, the current code will be completed via our novel graph-based code completion algorithm. Empirical evaluation on several real-world systems and human subjects shows that GraPacc has a high level of accuracy and a better level of usefulness than existing tools.},
  isbn = {978-1-4673-1067-3},
  keywords = {_tablet},
  series = {{{ICSE}} '12},
  venue = {Piscataway, NJ, USA}
}

@inproceedings{nguyen_learning_2016,
  title = {Learning {{API Usages}} from {{Bytecode}}: {{A Statistical Approach}}},
  shorttitle = {Learning {{API Usages}} from {{Bytecode}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Software Engineering}}},
  author = {Nguyen, Tam The and Pham, Hung Viet and Vu, Phong Minh and Nguyen, Tung Thanh},
  date = {2016},
  pages = {416--427},
  publisher = {{ACM}},
  doi = {10.1145/2884781.2884873},
  url = {http://doi.acm.org/10.1145/2884781.2884873},
  urldate = {2016-06-19},
  abstract = {Mobile app developers rely heavily on standard API frameworks and libraries. However, learning API usages is often challenging due to the fast-changing nature of API frameworks for mobile systems and the insufficiency of API documentation and source code examples. In this paper, we propose a novel approach to learn API usages from bytecode of Android mobile apps. Our core contributions include HAPI, a statistical model of API usages and three algorithms to extract method call sequences from apps' bytecode, to train HAPI based on those sequences, and to recommend method calls in code completion using the trained HAPIs. Our empirical evaluation shows that our prototype tool can effectively learn API usages from 200 thousand apps containing 350 million method sequences. It recommends next method calls with top-3 accuracy of 90\% and outperforms baseline approaches on average 10–20\%.},
  isbn = {978-1-4503-3900-1},
  keywords = {_tablet,api usage,mobile apps,statistical model},
  series = {{{ICSE}} '16},
  venue = {New York, NY, USA}
}

@inproceedings{nguyen_recommending_2015,
  title = {Recommending {{API Usages}} for {{Mobile Apps}} with {{Hidden Markov Model}}},
  booktitle = {2015 30th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  author = {Nguyen, T. T. and Pham, H. V. and Vu, P. M. and Nguyen, T. T.},
  date = {2015-11},
  pages = {795--800},
  doi = {10.1109/ASE.2015.109},
  abstract = {Mobile apps often rely heavily on standard API frameworks and libraries. However, learning to use those APIs is often challenging due to the fast-changing nature of API frameworks and the insufficiency of documentation and code examples. This paper introduces DroidAssist, a recommendation tool for API usages of Android mobile apps. The core of DroidAssist is HAPI, a statistical, generative model of API usages based on Hidden Markov Model. With HAPIs trained from existing mobile apps, DroidAssist could perform code completion for method calls. It can also check existing call sequences to detect and repair suspicious (i.e. unpopular) API usages.},
  eventtitle = {2015 30th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  keywords = {Android mobile applications,Androids,API usage,API usage recommendation,application program interfaces,call sequences,code completion,Data mining,Documentation,DroidAssist recommendation tool,HAPI,hidden Markov model,hidden Markov models,Hidden Markov models,Humanoid robots,Maintenance engineering,method calls,Mobile communication,mobile computing,recommender systems,statistical analysis,Statistical code completion,statistical generative model,suspicious API usage detection,suspicious API usage repair}
}

@inproceedings{nguyen_statistical_2013,
  title = {A {{Statistical Semantic Language Model}} for {{Source Code}}},
  booktitle = {Proceedings of the 2013 9th {{Joint Meeting}} on {{Foundations}} of {{Software Engineering}}},
  author = {Nguyen, Tung Thanh and Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tien N.},
  date = {2013},
  pages = {532--542},
  publisher = {{ACM}},
  doi = {10.1145/2491411.2491458},
  url = {http://doi.acm.org/10.1145/2491411.2491458},
  urldate = {2015-12-08},
  abstract = {Recent research has successfully applied the statistical n-gram language model to show that source code exhibits a good level of repetition. The n-gram model is shown to have good predictability in supporting code suggestion and completion. However, the state-of-the-art n-gram approach to capture source code regularities/patterns is based only on the lexical information in a local context of the code units. To improve predictability, we introduce SLAMC, a novel statistical semantic language model for source code. It incorporates semantic information into code tokens and models the regularities/patterns of such semantic annotations, called sememes, rather than their lexemes. It combines the local context in semantic n-grams with the global technical concerns/functionality into an n-gram topic model, together with pairwise associations of program elements. Based on SLAMC, we developed a new code suggestion method, which is empirically evaluated on several projects to have relatively 18-68\% higher accuracy than the state-of-the-art approach.},
  isbn = {978-1-4503-2237-9},
  keywords = {_tablet,code completion,Statistical Semantic Language Model},
  series = {{{ESEC}}/{{FSE}} 2013},
  venue = {New York, NY, USA}
}

@online{noauthor_go_nodate,
  title = {Go at {{Google}}: {{Language Design}} in the {{Service}} of {{Software Engineering}}},
  url = {https://talks.golang.org/2012/splash.article},
  urldate = {2020-08-08},
  file = {/home/enrico/Zotero/storage/JCV5KWP7/splash.html}
}

@online{noauthor_null_nodate,
  title = {Null {{Safety}} - {{Kotlin Programming Language}}},
  journaltitle = {Kotlin},
  url = {https://kotlinlang.org/docs/reference/null-safety.html},
  urldate = {2020-08-08},
  file = {/home/enrico/Zotero/storage/TJCBEQAP/null-safety.html},
  langid = {english}
}

@article{noauthor_standardized_nodate,
  title = {Standardized Code Quality Benchmarking for Improving Software Maintainability}
}

@inproceedings{omar_active_2012,
  title = {Active {{Code Completion}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Software Engineering}}},
  author = {Omar, Cyrus and Yoon, YoungSeok and LaToza, Thomas D. and Myers, Brad A.},
  date = {2012},
  pages = {859--869},
  publisher = {{IEEE Press}},
  url = {http://dl.acm.org/citation.cfm?id=2337223.2337324},
  urldate = {2015-12-04},
  abstract = {Code completion menus have replaced standalone API browsers for most developers because they are more tightly integrated into the development workflow. Refinements to the code completion menu that incorporate additional sources of information have similarly been shown to be valuable, even relative to standalone counterparts offering similar functionality. In this paper, we describe active code completion, an architecture that allows library developers to introduce interactive and highly-specialized code generation interfaces, called palettes, directly into the editor. Using several empirical methods, we examine the contexts in which such a system could be useful, describe the design constraints governing the system architecture as well as particular code completion interfaces, and design one such system, named Graphite, for the Eclipse Java development environment. Using Graphite, we implement a palette for writing regular expressions as our primary example and conduct a small pilot study. In addition to showing the feasibility of this approach, it provides further evidence in support of the claim that integrating specialized code completion interfaces directly into the editor is valuable to professional developers.},
  isbn = {978-1-4673-1067-3},
  keywords = {_tablet},
  series = {{{ICSE}} '12},
  venue = {Piscataway, NJ, USA}
}

@article{pradel_typewriter_2020,
  title = {{{TypeWriter}}: {{Neural Type Prediction}} with {{Search}}-{{Based Validation}}},
  shorttitle = {{{TypeWriter}}},
  author = {Pradel, Michael and Gousios, Georgios and Liu, Jason and Chandra, Satish},
  date = {2020-03-06},
  url = {http://arxiv.org/abs/1912.03768},
  urldate = {2020-06-11},
  abstract = {Maintaining large code bases written in dynamically typed languages, such as JavaScript or Python, can be challenging due to the absence of type annotations: simple data compatibility errors proliferate, IDE support is limited, and APIs are hard to comprehend. Recent work attempts to address those issues through either static type inference or probabilistic type prediction. Unfortunately, static type inference for dynamic languages is inherently limited, while probabilistic approaches suffer from imprecision. This paper presents TypeWriter, the first combination of probabilistic type prediction with search-based refinement of predicted types. TypeWriter's predictor learns to infer the return and argument types for functions from partially annotated code bases by combining the natural language properties of code with programming language-level information. To validate predicted types, TypeWriter invokes a gradual type checker with different combinations of the predicted types, while navigating the space of possible type combinations in a feedback-directed manner. We implement the TypeWriter approach for Python and evaluate it on two code corpora: a multi-million line code base at Facebook and a collection of 1,137 popular open-source projects. We show that TypeWriter's type predictor achieves an F1 score of 0.64 (0.79) in the top-1 (top-5) predictions for return types, and 0.57 (0.80) for argument types, which clearly outperforms prior type prediction models. By combining predictions with search-based validation, TypeWriter can fully annotate between 14\% to 44\% of the files in a randomly selected corpus, while ensuring type correctness. A comparison with a static type inference tool shows that TypeWriter adds many more non-trivial types. TypeWriter currently suggests types to developers at Facebook and several thousands of types have already been accepted with minimal changes.},
  archivePrefix = {arXiv},
  eprint = {1912.03768},
  eprinttype = {arxiv},
  keywords = {Computer Science - Software Engineering}
}

@article{prahofer_static_2017,
  title = {Static {{Code Analysis}} of {{IEC}} 61131-3 {{Programs}}: {{Comprehensive Tool Support}} and {{Experiences}} from {{Large}}-{{Scale Industrial Application}}},
  shorttitle = {Static {{Code Analysis}} of {{IEC}} 61131-3 {{Programs}}},
  author = {Prahofer, Herbert and Angerer, Florian and Ramler, Rudolf and Grillenberger, Friedrich},
  date = {2017-02},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  shortjournal = {IEEE Trans. Ind. Inf.},
  volume = {13},
  pages = {37--47},
  issn = {1551-3203, 1941-0050},
  doi = {10.1109/TII.2016.2604760},
  url = {http://ieeexplore.ieee.org/document/7557072/},
  urldate = {2020-08-11},
  abstract = {Static code analysis techniques examine programs without actually executing them. The main benefits lie in improving software quality by detecting problematic code constructs and potential defects in early development stages. Today, static code analysis is a widely used quality assurance technique and numerous tools are available for established programming languages like C/C++, Java, or C\#. However, in the domain of PLC programming, static code analysis tools are still rare, although many properties of PLC programming languages are beneficial for static analysis techniques. Therefore, an approach and tool for static code analysis of IEC 61131-3 programs has been developed which is capable of detecting a range of issues commonly occurring in PLC programming. The approach employs different analysis methods, like pattern-matching on program structures, control flow and data flow analysis, and, especially, call graph and pointer analysis techniques. Based on results from an initial analysis project, where common issues for static analysis of PLC programs have been investigated, this paper illustrates adoption and extensions of analysis techniques for PLC programs and presents results from large-scale industrial application.},
  file = {/home/enrico/Zotero/storage/RPIIJ4DZ/Prahofer et al. - 2017 - Static Code Analysis of IEC 61131-3 Programs Comp.pdf},
  langid = {english},
  number = {1}
}

@article{prahofer_static_2017-1,
  title = {Static {{Code Analysis}} of {{IEC}} 61131-3 {{Programs}}: {{Comprehensive Tool Support}} and {{Experiences}} from {{Large}}-{{Scale Industrial Application}}},
  shorttitle = {Static {{Code Analysis}} of {{IEC}} 61131-3 {{Programs}}},
  author = {Prahofer, Herbert and Angerer, Florian and Ramler, Rudolf and Grillenberger, Friedrich},
  date = {2017-02},
  journaltitle = {IEEE Transactions on Industrial Informatics},
  shortjournal = {IEEE Trans. Ind. Inf.},
  volume = {13},
  pages = {37--47},
  issn = {1551-3203, 1941-0050},
  doi = {10.1109/TII.2016.2604760},
  url = {http://ieeexplore.ieee.org/document/7557072/},
  urldate = {2020-08-11},
  number = {1}
}

@inproceedings{prisca_language_2015,
  title = {A {{Language Independent User Adaptable Approach}} for {{Word Auto}}-{{Completion}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Intelligent Computer Communication}} and {{Processing}} ({{ICCP}})},
  author = {Prisca, S. and Potolea, R. and Dinsoreanu, M.},
  date = {2015-09},
  pages = {43--49},
  doi = {10.1109/ICCP.2015.7312604},
  abstract = {In this paper, we address the problem of word auto-completion for free text (e.g. messages, emails, articles, poems, etc.) written in different languages. We focus on improving the user experience by developing a user-oriented model that is able to learn different writing styles, while still providing initial predictions without any user written documents. We show that by learning from the user, the performance of an auto-completion system can be improved by up to 18\% compared to a generic, not user-adaptable approach. In order to keep query processing times low, we deploy a binary search technique that retrieves groups of words from an inverted index based on their first letters. This retrieval method reduces the query processing time by up to 80\%.},
  eventtitle = {2015 {{IEEE International Conference}} on {{Intelligent Computer Communication}} and {{Processing}} ({{ICCP}})},
  keywords = {_tablet,auto-completion system,binary search technique,Data models,Electronic mail,Encoding,free text,Indexes,inverted index,language independent user adaptable approach,natural language processing,query processing,query processing time,retrieval method,Runtime,Search problems,text analysis,user written document,user-oriented model,word auto-completion,Writing,writing style}
}

@article{radford_language_nodate,
  title = {Language {{Models}} Are {{Unsupervised Multitask Learners}}},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  pages = {24},
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  file = {/home/enrico/Zotero/storage/TD9UPAG8/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf},
  langid = {english}
}

@inproceedings{raghothaman_swim_2016,
  title = {{{SWIM}}: {{Synthesizing What I Mean}}: {{Code Search}} and {{Idiomatic Snippet Synthesis}}},
  shorttitle = {{{SWIM}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Software Engineering}}},
  author = {Raghothaman, Mukund and Wei, Yi and Hamadi, Youssef},
  date = {2016},
  pages = {357--367},
  publisher = {{ACM}},
  doi = {10.1145/2884781.2884808},
  url = {http://doi.acm.org/10.1145/2884781.2884808},
  urldate = {2016-06-19},
  abstract = {Modern programming frameworks come with large libraries, with diverse applications such as for matching regular expressions, parsing XML files and sending email. Programmers often use search engines such as Google and Bing to learn about existing APIs. In this paper, we describe SWIM, a tool which suggests code snippets given API-related natural language queries such as "generate md5 hash code". The query does not need to contain framework-specific trivia such as the type names or methods of interest. We translate user queries into the APIs of interest using clickthrough data from the Bing search engine. Then, based on patterns learned from open-source code repositories, we synthesize idiomatic code describing the use of these APIs. We introduce structured call sequences to capture API-usage patterns. Structured call sequences are a generalized form of method call sequences, with if-branches and while-loops to represent conditional and repeated API usage patterns, and are simple to extract and amenable to synthesis. We evaluated swim with 30 common C\# API-related queries received by Bing. For 70\% of the queries, the first suggested snippet was a relevant solution, and a relevant solution was present in the top 10 results for all benchmarked queries. The online portion of the workflow is also very responsive, at an average of 1.5 seconds per snippet.},
  isbn = {978-1-4503-3900-1},
  keywords = {_tablet},
  series = {{{ICSE}} '16},
  venue = {New York, NY, USA}
}

@inproceedings{raychev_code_2014,
  title = {Code {{Completion}} with {{Statistical Language Models}}},
  booktitle = {Proceedings of the 35th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Raychev, Veselin and Vechev, Martin and Yahav, Eran},
  date = {2014},
  pages = {419--428},
  publisher = {{ACM}},
  doi = {10.1145/2594291.2594321},
  url = {http://doi.acm.org/10.1145/2594291.2594321},
  urldate = {2015-12-04},
  abstract = {We address the problem of synthesizing code completions for programs using APIs. Given a program with holes, we synthesize completions for holes with the most likely sequences of method calls. Our main idea is to reduce the problem of code completion to a natural-language processing problem of predicting probabilities of sentences. We design a simple and scalable static analysis that extracts sequences of method calls from a large codebase, and index these into a statistical language model. We then employ the language model to find the highest ranked sentences, and use them to synthesize a code completion. Our approach is able to synthesize sequences of calls across multiple objects together with their arguments. Experiments show that our approach is fast and effective. Virtually all computed completions typecheck, and the desired completion appears in the top 3 results in 90\% of the cases.},
  isbn = {978-1-4503-2784-8},
  keywords = {_tablet},
  series = {{{PLDI}} '14},
  venue = {New York, NY, USA}
}

@inproceedings{raychev_probabilistic_2016,
  title = {Probabilistic {{Model}} for {{Code}} with {{Decision Trees}}},
  booktitle = {Proceedings of the 2016 {{ACM SIGPLAN International Conference}} on {{Object}}-{{Oriented Programming}}, {{Systems}}, {{Languages}}, and {{Applications}}},
  author = {Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
  date = {2016},
  pages = {731--747},
  publisher = {{ACM}},
  doi = {10.1145/2983990.2984041},
  url = {http://doi.acm.org/10.1145/2983990.2984041},
  urldate = {2019-11-09},
  abstract = {In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc). The key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy. Our approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82\% and 69\%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy.},
  isbn = {978-1-4503-4444-9},
  keywords = {Code Completion,Decision Trees,Probabilistic Models of Code},
  series = {{{OOPSLA}} 2016},
  venue = {New York, NY, USA}
}

@article{raychev_probabilistic_nodate,
  title = {Probabilistic {{Model}} for {{Code}} with {{Decision Trees}}},
  author = {Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
  pages = {17},
  abstract = {In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).},
  file = {/home/enrico/Zotero/storage/CG4K8ECH/Raychev et al. - Probabilistic Model for Code with Decision Trees.pdf},
  langid = {english}
}

@inproceedings{riaz_systematic_2009,
  title = {A Systematic Review of Software Maintainability Prediction and Metrics},
  booktitle = {2009 3rd {{International Symposium}} on {{Empirical Software Engineering}} and {{Measurement}}},
  author = {Riaz, Mehwish and Mendes, Emilia and Tempero, Ewan},
  date = {2009-10},
  pages = {367--377},
  publisher = {{IEEE}},
  location = {{Lake Buena Vista, FL, USA}},
  doi = {10.1109/ESEM.2009.5314233},
  url = {http://ieeexplore.ieee.org/document/5314233/},
  urldate = {2020-08-11},
  abstract = {This paper presents the results of a systematic review conducted to collect evidence on software maintainability prediction and metrics. The study was targeted at the software quality attribute of maintainability as opposed to the process of software maintenance. The evidence was gathered from the selected studies against a set of meaningful and focused questions. 710 studies were initially retrieved; however of these only 15 studies were selected; their quality was assessed; data extraction was performed; and data was synthesized against the research questions. Our results suggest that there is little evidence on the effectiveness of software maintainability prediction techniques and models.},
  eventtitle = {2009 3rd {{International Symposium}} on {{Empirical Software Engineering}} and {{Measurement}} ({{ESEM}})},
  file = {/home/enrico/Zotero/storage/XH3Z2HEQ/Riaz et al. - 2009 - A systematic review of software maintainability pr.pdf},
  isbn = {978-1-4244-4842-5},
  langid = {english}
}

@inproceedings{robbes_how_2008,
  title = {How {{Program History Can Improve Code Completion}}},
  booktitle = {23rd {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}, 2008. {{ASE}} 2008},
  author = {Robbes, R. and Lanza, M.},
  date = {2008-09},
  pages = {317--326},
  doi = {10.1109/ASE.2008.42},
  abstract = {Code completion is a widely used productivity tool. It takes away the burden of remembering and typing the exact names of methods or classes: As a developer starts typing a name, it provides a progressively refined list of candidates matching the name. However, the candidate list always comes in alphabetic order, i.e., the environment is only second-guessing the name based on pattern matching. Finding the correct candidate can be cumbersome or slower than typing the full name. We present an approach to improve code completion with program history. We define a benchmark measuring the accuracy and usefulness of a code completion engine. Further, we use the change history data to also improve the results offered by code completion tools. Finally, we propose an alternative interface for completion tools.},
  eventtitle = {23rd {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}}, 2008. {{ASE}} 2008},
  keywords = {_tablet,Benchmark testing,code completion,codes,Computer languages,Engines,History,Information resources,Measurement standards,Pattern matching,Performance evaluation,Productivity,productivity tool,Switches}
}

@article{robillard_recommendation_2010,
  title = {Recommendation {{Systems}} for {{Software Engineering}}},
  author = {Robillard, M.P. and Walker, R.J. and Zimmermann, T.},
  date = {2010-07},
  journaltitle = {IEEE Software},
  volume = {27},
  pages = {80--86},
  issn = {0740-7459},
  doi = {10.1109/MS.2009.161},
  abstract = {Software development can be challenging because of the large information spaces that developers must navigate. Without assistance, developers can become bogged down and spend a disproportionate amount of their time seeking information at the expense of other value-producing tasks. Recommendation systems for software engineering (RSSEs) are software tools that can assist developers with a wide range of activities, from reusing code to writing effective bug reports. The authors provide an overview of recommendation systems for software engineering: what they are, what they can do for developers, and what they might do in the future.},
  keywords = {_tablet,bug reports,coding tools and techniques,design tools and techniques,development tools,information space,programming environments,recommendation system,recommender systems,software construction tools,Software Development,software engineering,software tool,Software tools,time seeking information,value-producing task},
  number = {4}
}

@book{robillard_recommendation_2014,
  title = {Recommendation {{Systems}} in {{Software Engineering}}},
  author = {Robillard, Martin P.},
  date = {2014-01-01},
  publisher = {{Springer Science \& Business}},
  url = {http://www.springer.com/computer/swe/book/978-3-642-45134-8},
  abstract = {With the growth of public and private data stores and the emergence of off-the-shelf data-mining technology, recommendation systems have emerged that specifically address the unique challenges of navigating and interpreting software engineering data. This book collects, structures, and formalizes knowledge on recommendation systems in software engineering. It adopts a pragmatic approach with an explicit focus on system design, implementation, and evaluation. The book is divided into three parts: Part I Techniques introduces basics for building recommenders in software engineering, including techniques for collecting and processing software engineering data, but also for presenting recommendations to users as part of their workflow. Part II Evaluation summarizes methods and experimental designs for evaluating recommendations in software engineering. Part III Applications describes needs, issues, and solution concepts involved in entire recommendation systems for specific software engineering tasks, focusing on the engineering insights required to make effective recommendations. The book is complemented by the webpage rsse.org/book, which includes free supplemental materials for readers of this book and anyone interested in recommendation systems in software engineering, including lecture slides, data sets, source code, and an overview of people, groups, papers, and tools with regard to recommendation systems in software engineering. The book is particularly well-suited for graduate students and researchers building new recommendation systems for software engineering applications or in other high-tech fields. It may also serve as the basis for graduate courses on recommendation systems, applied data mining, or software engineering. Software engineering practitioners developing recommendation systems or similar applications with predictive functionality will also benefit from the broad spectrum of topics covered.},
  isbn = {978-3-642-45135-5},
  keywords = {_tablet,Computers / Programming / Open Source,Computers / Software Development & Engineering / General,Computers / Software Development & Engineering / Tools},
  pagetotal = {560}
}

@inproceedings{schein_methods_2002,
  title = {Methods and {{Metrics}} for {{Cold}}-{{Start Recommendations}}},
  booktitle = {Proceedings of the 25th {{Annual International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Schein, Andrew I. and Popescul, Alexandrin and Ungar, Lyle H. and Pennock, David M.},
  date = {2002},
  pages = {253--260},
  publisher = {{ACM}},
  doi = {10.1145/564376.564421},
  url = {http://doi.acm.org/10.1145/564376.564421},
  urldate = {2016-02-06},
  abstract = {We have developed a method for recommending items that combines content and collaborative data under a single probabilistic framework. We benchmark our algorithm against a naïve Bayes classifier on the cold-start problem, where we wish to recommend items that no one in the community has yet rated. We systematically explore three testing methodologies using a publicly available data set, and explain how these methods apply to specific real-world applications. We advocate heuristic recommenders when benchmarking to give competent baseline performance. We introduce a new performance metric, the CROC curve, and demonstrate empirically that the various components of our testing strategy combine to obtain deeper understanding of the performance characteristics of recommender systems. Though the emphasis of our testing is on cold-start recommending, our methods for recommending and evaluation are general.},
  isbn = {1-58113-561-0},
  keywords = {collaborative filtering,content-based filtering,graphical models,information retrieval,Performance evaluation,recommender systems},
  series = {{{SIGIR}} '02},
  venue = {New York, NY, USA}
}

@inproceedings{schmedding_clean_2015,
  title = {Clean {{Code}}-Ein Neues {{Ziel}} Im {{Software}}-{{Praktikum}}.},
  booktitle = {{{SEUH}}},
  author = {Schmedding, Doris and Vasileva, Anna and Remmers, Julian},
  date = {2015},
  pages = {81--91},
  file = {/home/enrico/Zotero/storage/8IEJRBXF/Schmedding et al. - 2015 - Clean Code-ein neues Ziel im Software-Praktikum..pdf}
}

@article{schmedding_clean_2015-1,
  title = {Clean Code – ein neues Ziel im Software-Praktikum},
  author = {Schmedding, Doris and Vasileva, Anna and Remmers, Julian},
  date = {2015},
  pages = {11},
  file = {/home/enrico/Zotero/storage/T82UG2SM/Schmedding et al. - 2015 - Clean Code – ein neues Ziel im Software-Praktikum.pdf},
  langid = {german}
}

@article{sjoberg_questioning_nodate,
  title = {Questioning {{Software Maintenance Metrics}}: {{A Comparative Case Study}}},
  author = {Sjøberg, Dag I K and Sjoberg, Dag and Anda, Bente and Mockus, Audris},
  pages = {4},
  abstract = {Context: Many metrics are used in software engineering research as surrogates for maintainability of software systems. Aim: Our aim was to investigate whether such metrics are consistent among themselves and the extent to which they predict maintenance effort at the entire system level. Method: The Maintainability Index, a set of structural measures, two code smells (Feature Envy and God Class) and size were applied to a set of four functionally equivalent systems. The metrics were compared with each other and with the outcome of a study in which six developers were hired to perform three maintenance tasks on the same systems. Results: The metrics were not mutually consistent. Only system size and low cohesion were strongly associated with increased maintenance effort. Conclusion: Apart from size, surrogate maintainability measures may not reflect future maintenance effort. Surrogates need to be evaluated in the contexts for which they will be used. While traditional metrics are used to identify problematic areas in the code, the improvements of the worst areas may, inadvertently, lead to more problems for the entire system. Our results suggest that local improvements should be accompanied by an evaluation at the system level.},
  file = {/home/enrico/Zotero/storage/4RJYJD7C/Sjøberg et al. - Questioning Software Maintenance Metrics A Compar.pdf},
  langid = {english}
}

@article{sun_treegen_2019,
  title = {{{TreeGen}}: {{A Tree}}-{{Based Transformer Architecture}} for {{Code Generation}}},
  shorttitle = {{{TreeGen}}},
  author = {Sun, Zeyu and Zhu, Qihao and Xiong, Yingfei and Sun, Yican and Mou, Lili and Zhang, Lu},
  date = {2019-11-28},
  url = {http://arxiv.org/abs/1911.09983},
  urldate = {2020-01-01},
  abstract = {A code generation system generates programming language code based on an input natural language description. State-of-the-art approaches rely on neural networks for code generation. However, these code generators suffer from two problems. One is the long dependency problem, where a code element often depends on another far-away code element. A variable reference, for example, depends on its definition, which may appear quite a few lines before. The other problem is structure modeling, as programs contain rich structural information. In this paper, we propose a novel tree-based neural architecture, TreeGen, for code generation. TreeGen uses the attention mechanism of Transformers to alleviate the long-dependency problem, and introduces a novel AST reader (encoder) to incorporate grammar rules and AST structures into the network. We evaluated TreeGen on a Python benchmark, HearthStone, and two semantic parsing benchmarks, ATIS and GEO. TreeGen outperformed the previous state-of-the-art approach by 4.5 percentage points on HearthStone, and achieved the best accuracy among neural network-based approaches on ATIS (89.1\%) and GEO (89.6\%). We also conducted an ablation test to better understand each component of our model.},
  archivePrefix = {arXiv},
  eprint = {1911.09983},
  eprinttype = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering}
}

@article{svyatkovskiy_fast_2020,
  title = {Fast and {{Memory}}-{{Efficient Neural Code Completion}}},
  author = {Svyatkovskiy, Alexey and Lee, Sebastian and Hadjitofi, Anna and Riechert, Maik and Franco, Juliana and Allamanis, Miltiadis},
  date = {2020-04-29},
  url = {http://arxiv.org/abs/2004.13651},
  urldate = {2020-06-10},
  abstract = {Code completion is one of the most widely used features of modern integrated development environments (IDEs). Deep learning has recently made significant progress in the statistical prediction of source code. However, state-of-the-art neural network models consume prohibitively large amounts of memory, causing computational burden to the development environment, especially when deployed in lightweight client devices. In this work, we reframe neural code completion from a generation task to a task of learning to rank the valid completion suggestions computed from static analyses. By doing so, we are able to design and test a variety of deep neural network model configurations. One of our best models consumes 6 MB of RAM, computes a single suggestion in 8 ms, and achieves 90\% recall in its top five suggestions. Our models outperform standard language modeling code completion techniques in terms of predictive performance, computational speed, and memory efficiency. Furthermore, they learn about code semantics from the natural language aspects of the code (e.g. identifier names) and can generalize better to previously unseen code.},
  archivePrefix = {arXiv},
  eprint = {2004.13651},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/UAXIHWL7/Svyatkovskiy et al. - 2020 - Fast and Memory-Efficient Neural Code Completion.pdf},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering}
}

@article{svyatkovskiy_intellicode_2020,
  title = {{{IntelliCode Compose}}: {{Code Generation Using Transformer}}},
  shorttitle = {{{IntelliCode Compose}}},
  author = {Svyatkovskiy, Alexey and Deng, Shao Kun and Fu, Shengyu and Sundaresan, Neel},
  date = {2020-05-16},
  url = {http://arxiv.org/abs/2005.08025},
  urldate = {2020-06-11},
  abstract = {In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments. In this paper, we introduce IntelliCode Compose \$-\$ a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, \$C\textbackslash textbackslash\#\$, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook. Our best model yields an average edit similarity of \$86.7\textbackslash textbackslash\%\$ and a perplexity of 1.82 for Python programming language.},
  archivePrefix = {arXiv},
  eprint = {2005.08025},
  eprinttype = {arxiv},
  file = {/home/enrico/Zotero/storage/N59K8XW8/Svyatkovskiy et al. - 2020 - IntelliCode Compose Code Generation Using Transfo.pdf},
  keywords = {Computer Science - Computation and Language,Computer Science - Software Engineering,Encoding,gpt-2}
}

@article{svyatkovskiy_intellicode_2020-1,
  title = {{{IntelliCode Compose}}: {{Code Generation Using Transformer}}},
  shorttitle = {{{IntelliCode Compose}}},
  author = {Svyatkovskiy, Alexey and Deng, Shao Kun and Fu, Shengyu and Sundaresan, Neel},
  date = {2020-05-16},
  url = {http://arxiv.org/abs/2005.08025},
  urldate = {2020-06-11},
  abstract = {In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments. In this paper, we introduce IntelliCode Compose \$-\$ a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, \$C\textbackslash textbackslash\#\$, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook. Our best model yields an average edit similarity of \$86.7\textbackslash textbackslash\%\$ and a perplexity of 1.82 for Python programming language.},
  archivePrefix = {arXiv},
  eprint = {2005.08025},
  eprinttype = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Software Engineering}
}

@inproceedings{svyatkovskiy_pythia_2019,
  title = {Pythia: {{AI}}-{{Assisted Code Completion System}}},
  shorttitle = {Pythia},
  booktitle = {Proceedings of the 25th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Svyatkovskiy, Alexey and Zhao, Ying and Fu, Shengyu and Sundaresan, Neel},
  date = {2019-07-25},
  pages = {2727--2735},
  publisher = {{Association for Computing Machinery}},
  doi = {10.1145/3292500.3330699},
  url = {https://doi.org/10.1145/3292500.3330699},
  urldate = {2020-06-08},
  abstract = {In this paper, we propose a novel end-to-end approach for AI-assisted code completion called Pythia. It generates ranked lists of method and API recommendations which can be used by software developers at edit time. The system is currently deployed as part of Intellicode extension in Visual Studio Code IDE. Pythia exploits state-of-the-art large-scale deep learning models trained on code contexts extracted from abstract syntax trees. It is designed to work at a high throughput predicting the best matching code completions on the order of 100 ms. We describe the architecture of the system, perform comparisons to frequency-based approach and invocation-based Markov Chain language model, and discuss challenges serving Pythia models on lightweight client devices. The offline evaluation results obtained on 2700 Python open source software GitHub repositories show a top-5 accuracy of 92\%, surpassing the baseline models by 20\% averaged over classes, for both intra and cross-project settings.},
  isbn = {978-1-4503-6201-6},
  keywords = {code completion,naturalness of software,neural networks},
  series = {{{KDD}} '19},
  venue = {Anchorage, AK, USA}
}

@online{tabnine_autocompletion_2019,
  title = {Autocompletion with {{Deep Learning}}},
  author = {{TabNine}},
  date = {2019-07-15},
  url = {https://tabnine.com/blog/deep/},
  urldate = {2020-02-20},
  abstract = {TabNine is the all-language autocompleter. We use deep learning to help you write code faster.}
}

@unpublished{vechev_pldi_2015,
  title = {{{PLDI}} 2015 {{Tutorial}}: {{Machine Learning}} for {{Code Analysis}}},
  author = {Vechev, Martin and Raychev, Veselin},
  date = {2015-06-14},
  url = {https://www.sri.inf.ethz.ch/ml4code-tutorial}
}

@inproceedings{wallach_topic_2006,
  title = {Topic {{Modeling}}: {{Beyond Bag}}-of-{{Words}}},
  shorttitle = {Topic {{Modeling}}},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Machine Learning}}},
  author = {Wallach, Hanna M.},
  date = {2006},
  pages = {977--984},
  publisher = {{ACM}},
  doi = {10.1145/1143844.1143967},
  url = {http://doi.acm.org/10.1145/1143844.1143967},
  urldate = {2015-12-21},
  abstract = {Some models of textual corpora employ text generation methods involving n-gram statistics, while others use latent topic variables inferred using the "bag-of-words" assumption, in which word order is ignored. Previously, these methods have not been combined. In this work, I explore a hierarchical generative probabilistic model that incorporates both n-gram statistics and latent topic variables by extending a unigram topic model to include properties of a hierarchical Dirichlet bigram language model. The model hyperparameters are inferred using a Gibbs EM algorithm. On two data sets, each of 150 documents, the new model exhibits better predictive accuracy than either a hierarchical Dirichlet bigram language model or a unigram topic model. Additionally, the inferred topics are less dominated by function words than are topics discovered using unigram statistics, potentially making them more meaningful.},
  isbn = {1-59593-383-2},
  keywords = {_tablet},
  series = {{{ICML}} '06},
  venue = {New York, NY, USA}
}

@inproceedings{wang_active_2014,
  title = {Active {{Code Search}}: {{Incorporating User Feedback}} to {{Improve Code Search Relevance}}},
  shorttitle = {Active {{Code Search}}},
  booktitle = {Proceedings of the 29th {{ACM}}/{{IEEE International Conference}} on {{Automated Software Engineering}}},
  author = {Wang, Shaowei and Lo, David and Jiang, Lingxiao},
  date = {2014},
  pages = {677--682},
  publisher = {{ACM}},
  doi = {10.1145/2642937.2642947},
  url = {http://doi.acm.org/10.1145/2642937.2642947},
  urldate = {2015-12-05},
  abstract = {Code search techniques return relevant code fragments given a user query. They typically work in a passive mode: given a user query, a static list of code fragments sorted by the relevance scores decided by a code search technique is returned to the user. A user will go through the sorted list of returned code fragments from top to bottom. As the user checks each code fragment one by one, he or she will naturally form an opinion about the true relevance of the code fragment. In an active model, those opinions will be taken as feedbacks to the search engine for refining result lists. In this work, we incorporate users' opinion on the results from a code search engine to refine result lists: as a user forms an opinion about one result, our technique takes this opinion as feedback and leverages it to re-order the results to make truly relevant results appear earlier in the list. The refinement results can also be cached to potentially improve future code search tasks. We have built our active refinement technique on top of a state-of-the-art code search engine—Portfolio. Our technique improves Portfolio in terms of Normalized Discounted Cumulative Gain (NDCG) by more than 11.3\%, from 0.738 to 0.821.},
  isbn = {978-1-4503-3013-8},
  keywords = {_tablet,active learning,code search,user feedback},
  series = {{{ASE}} '14},
  venue = {New York, NY, USA}
}

@online{wichers_source_nodate,
  title = {Source {{Code Analysis Tools}} | {{OWASP}}},
  author = {Wichers, Dave and Worcel, Eitan},
  url = {https://owasp.org/www-community/Source_Code_Analysis_Tools},
  urldate = {2020-08-11},
  abstract = {Source Code Analysis Tools on the main website for The OWASP Foundation. OWASP is a nonprofit foundation that works to improve the security of software.},
  file = {/home/enrico/Zotero/storage/IZI5VABD/Source_Code_Analysis_Tools.html},
  langid = {english}
}

@article{xu_incorporating_2020,
  title = {Incorporating {{External Knowledge}} through {{Pre}}-{{Training}} for {{Natural Language}} to {{Code Generation}}},
  author = {Xu, Frank F. and Jiang, Zhengbao and Yin, Pengcheng and Vasilescu, Bogdan and Neubig, Graham},
  date = {2020-04-19},
  url = {http://arxiv.org/abs/2004.09015},
  urldate = {2020-06-23},
  abstract = {Open-domain code generation aims to generate code in a general-purpose programming language (such as Python) from natural language (NL) intents. Motivated by the intuition that developers usually retrieve resources on the web when writing code, we explore the effectiveness of incorporating two varieties of external knowledge into NL-to-code generation: automatically mined NL-code pairs from the online programming QA forum StackOverflow and programming language API documentation. Our evaluations show that combining the two sources with data augmentation and retrieval-based data re-sampling improves the current state-of-the-art by up to 2.2\% absolute BLEU score on the code generation testbed CoNaLa. The code and resources are available at https://github.com/neulab/external-knowledge-codegen.},
  archivePrefix = {arXiv},
  eprint = {2004.09015},
  eprinttype = {arxiv},
  keywords = {Computer Science - Computation and Language}
}

@inproceedings{yamashita_thresholds_2016,
  title = {Thresholds for {{Size}} and {{Complexity Metrics}}: {{A Case Study}} from the {{Perspective}} of {{Defect Density}}},
  shorttitle = {Thresholds for {{Size}} and {{Complexity Metrics}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security}} ({{QRS}})},
  author = {Yamashita, Kazuhiro and Huang, Changyun and Nagappan, Meiyappan and Kamei, Yasutaka and Mockus, Audris and Hassan, Ahmed E. and Ubayashi, Naoyasu},
  date = {2016-08},
  pages = {191--201},
  publisher = {{IEEE}},
  location = {{Vienna, Austria}},
  doi = {10.1109/QRS.2016.31},
  url = {http://ieeexplore.ieee.org/document/7589799/},
  urldate = {2020-08-11},
  abstract = {Practical guidelines on what code has better quality are in great demand. For example, it is reasonable to expect the most complex code to be buggy. Structuring code into reasonably sized files and classes also appears to be prudent. Many attempts to determine (or declare) risk thresholds for various code metrics have been made. In this paper we want to examine the applicability of such thresholds. Hence, we replicate a recently published technique for calculating metric thresholds to determine high-risk files based on code size (LOC and number of methods), and complexity (cyclomatic complexity and module interface coupling) using a very large set of open and closed source projects written primarily in Java. We relate the threshold-derived risk to (a) the probability that a file would have a defect, and (b) the defect density of the files in the highrisk group. We find that the probability of a file having a defect is higher in the very high-risk group with a few exceptions. This is particularly pronounced when using size thresholds. Surprisingly, the defect density was uniformly lower in the very high-risk group of files. Our results suggest that, as expected, less code is associated with fewer defects. However, the same amount of code in large and complex files was associated with fewer defects than when located in smaller and less complex files. Hence we conclude that risk thresholds for size and complexity metrics have to be used with caution if at all. Our findings have immediate practical implications: the redistribution of Java code into smaller and less complex files may be counterproductive.},
  eventtitle = {2016 {{IEEE International Conference}} on {{Software Quality}}, {{Reliability}} and {{Security}} ({{QRS}})},
  file = {/home/enrico/Zotero/storage/VIIZEFUH/Yamashita et al. - 2016 - Thresholds for Size and Complexity Metrics A Case.pdf},
  isbn = {978-1-5090-4127-5},
  langid = {english}
}

@article{yuan_api_2019,
  title = {{{API Recommendation}} for {{Event}}-{{Driven Android Application Development}}},
  author = {Yuan, Weizhao and Nguyen, Hoang H. and Jiang, Lingxiao and Chen, Yuting and Zhao, Jianjun and Yu, Haibo},
  date = {2019-03-01},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  volume = {107},
  pages = {30--47},
  issn = {0950-5849},
  doi = {10.1016/j.infsof.2018.10.010},
  url = {http://www.sciencedirect.com/science/article/pii/S0950584918302222},
  urldate = {2019-03-24},
  abstract = {Context Software development is increasingly dependent on existing libraries. Developers need help to find suitable library APIs. Although many studies have been proposed to recommend relevant functional APIs that can be invoked for implementing a functionality, few studies have paid attention to an orthogonal need associated with event-driven programming frameworks, such as the Android framework. In addition to invoking functional APIs, Android developers need to know where to place functional code according to various events that may be triggered within the framework. Objective This paper aims to develop an API recommendation engine for Android application development that can recommend both (1) functional APIs for implementing a functionality and (2) the event callback APIs that are to be overridden to contain the functional code. Method We carry out an empirical study on actual Android programming questions from StackOverflow to confirm the need of recommending callbacks. Then we build Android-specific API databases to contain the correlations among various functionalities and APIs, based on customized parsing of code snippets and natural language processing of texts in Android tutorials and SDK documents, and then textual and code similarity metrics are adapted for recommending relevant APIs. Results We have evaluated our prototype recommendation engine, named LibraryGuru, with about 1500 questions on Android programming from StackOverflow, and demonstrated that our top-5 results on recommending callbacks and functional APIs can on estimate achieve up to 43.5\% and 50.9\% respectively in precision, 24.6\% and 32.5\% respectively in mean average precision (MAP) scores, and 51.1\% and 44.0\% respectively in recall. Conclusion We conclude that it is important and possible to recommend both functional APIs and callbacks for Android application development, and future work is needed to take more data sources into consideration to make more relevant recommendations for developers’ needs.},
  keywords = {Android programming,API recommendation,Code search,Event callbacks,Information retrieval}
}

@inproceedings{yuan_libraryguru_2018,
  title = {{{LibraryGuru}}: {{API Recommendation}} for {{Android Developers}}},
  shorttitle = {{{LibraryGuru}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Software Engineering}}: {{Companion Proceeedings}}},
  author = {Yuan, Weizhao and Nguyen, Hoang H. and Jiang, Lingxiao and Chen, Yuting},
  date = {2018},
  pages = {364--365},
  publisher = {{ACM}},
  doi = {10.1145/3183440.3195011},
  url = {http://doi.acm.org/10.1145/3183440.3195011},
  urldate = {2019-03-24},
  abstract = {Developing modern mobile applications often require the uses of many libraries specific for the mobile platform, which can be overwhelmingly too many for application developers to find what are needed for a functionality and where and how to use them properly. This paper presents a tool, named LibraryGuru, to recommend suitable Android APIs for given functionality descriptions. It not only recommends functional APIs that can be invoked for implementing the functionality, but also recommends event callback APIs that are inherent in the Android framework and need to be overridden in the application. LibraryGuru internally builds correlation databases among various functionality descriptions and Android APIs. These correlations are extracted from Android development tutorials and SDK documents with domain-specific code parsing and natural language processing techniques adapted for functional APIs and event callback APIs separately, and are matched against functionality queries to recommend relevant APIs for developers. LibraryGuru is publicly accessible at http://libraryguru.info, and a demo video is available at https://youtu.be/f7MtjliUM-4.},
  isbn = {978-1-4503-5663-3},
  series = {{{ICSE}} '18},
  venue = {New York, NY, USA}
}

@inproceedings{zhang_automatic_2012,
  title = {Automatic {{Parameter Recommendation}} for {{Practical API Usage}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Software Engineering}}},
  author = {Zhang, Cheng and Yang, Juyuan and Zhang, Yi and Fan, Jing and Zhang, Xin and Zhao, Jianjun and Ou, Peizhao},
  date = {2012},
  pages = {826--836},
  publisher = {{IEEE Press}},
  url = {http://dl.acm.org/citation.cfm?id=2337223.2337321},
  urldate = {2015-02-19},
  abstract = {Programmers extensively use application programming interfaces (APIs) to leverage existing libraries and frameworks. However, correctly and efficiently choosing and using APIs from unfamiliar libraries and frameworks is still a non-trivial task. Programmers often need to ruminate on API documentations (that are often incomplete) or inspect code examples (that are often absent) to learn API usage patterns. Recently, various techniques have been proposed to alleviate this problem by creating API summarizations, mining code examples, or showing common API call sequences. However, few techniques focus on recommending API parameters. In this paper, we propose an automated technique, called Precise, to address this problem. Differing from common code completion systems, Precise mines existing code bases, uses an abstract usage instance representation for each API usage example, and then builds a parameter usage database. Upon a request, Precise queries the database for abstract usage instances in similar contexts and generates parameter candidates by concretizing the instances adaptively. The experimental results show that our technique is more general and applicable than existing code completion systems, specially, 64\% of the parameter recommendations are useful and 53\% of the recommendations are exactly the same as the actual parameters needed. We have also performed a user study to show our technique is useful in practice.},
  isbn = {978-1-4673-1067-3},
  keywords = {_tablet},
  series = {{{ICSE}} '12},
  venue = {Piscataway, NJ, USA}
}

@inproceedings{zhang_bing_2016,
  title = {Bing {{Developer Assistant}}: {{Improving Developer Productivity}} by {{Recommending Sample Code}}},
  shorttitle = {Bing {{Developer Assistant}}},
  booktitle = {Proceedings of the 2016 24th {{ACM SIGSOFT International Symposium}} on {{Foundations}} of {{Software Engineering}}},
  author = {Zhang, Hongyu and Jain, Anuj and Khandelwal, Gaurav and Kaushik, Chandrashekhar and Ge, Scott and Hu, Wenxiang},
  date = {2016},
  pages = {956--961},
  publisher = {{ACM}},
  doi = {10.1145/2950290.2983955},
  url = {http://doi.acm.org/10.1145/2950290.2983955},
  abstract = {In programming practice, developers often need sample code in order to learn how to solve a programming-related problem. For example, how to reuse an Application Programming Interface (API) of a large-scale software library and how to implement a certain functionality. We believe that previously written code can help developers understand how others addressed the similar problems and can help them write new programs. We develop a tool called Bing Developer Assistant (BDA), which improves developer productivity by recommending sample code mined from public software repositories (such as GitHub) and web pages (such as Stack Overflow). BDA can automatically mine code snippets that implement an API or answer a code search query. It has been implemented as a free-downloadable extension of Microsoft Visual Studio and has received more than 670K downloads since its initial release in December 2014. BDA is publicly available at: http://aka.ms/devassistant.},
  isbn = {978-1-4503-4218-6},
  keywords = {_tablet,API,API Usage Extraction,code search,github,software reuse},
  series = {{{FSE}} 2016},
  venue = {New York, NY, USA}
}

@inproceedings{zhang_novel_2019,
  title = {A {{Novel Neural Source Code Representation Based}} on {{Abstract Syntax Tree}}},
  booktitle = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  author = {Zhang, Jian and Wang, Xu and Zhang, Hongyu and Sun, Hailong and Wang, Kaixuan and Liu, Xudong},
  date = {2019-05},
  pages = {783--794},
  publisher = {{IEEE}},
  location = {{Montreal, QC, Canada}},
  doi = {10.1109/ICSE.2019.00086},
  url = {https://ieeexplore.ieee.org/document/8812062/},
  urldate = {2020-08-02},
  abstract = {Exploiting machine learning techniques for analyzing programs has attracted much attention. One key problem is how to represent code fragments well for follow-up analysis. Traditional information retrieval based methods often treat programs as natural language texts, which could miss important semantic information of source code. Recently, state-of-the-art studies demonstrate that abstract syntax tree (AST) based neural models can better represent source code. However, the sizes of ASTs are usually large and the existing models are prone to the long-term dependency problem. In this paper, we propose a novel AST-based Neural Network (ASTNN) for source code representation. Unlike existing models that work on entire ASTs, ASTNN splits each large AST into a sequence of small statement trees, and encodes the statement trees to vectors by capturing the lexical and syntactical knowledge of statements. Based on the sequence of statement vectors, a bidirectional RNN model is used to leverage the naturalness of statements and finally produce the vector representation of a code fragment. We have applied our neural network based source code representation method to two common program comprehension tasks: source code classification and code clone detection. Experimental results on the two tasks indicate that our model is superior to state-of-the-art approaches.},
  eventtitle = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  file = {/home/enrico/Zotero/storage/NQM9D52E/Zhang et al. - 2019 - A Novel Neural Source Code Representation Based on.pdf},
  isbn = {978-1-72810-869-8},
  langid = {english}
}


